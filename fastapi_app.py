# fastapi_app.py
# Load environment variables FIRST before any other imports
from dotenv import load_dotenv
load_dotenv()

import os
import random
import threading
from io import BytesIO
from datetime import datetime, timedelta
# security & upload helpers
from utils_security_helpers import (
    get_password_hash,
    verify_password,
    save_upload_sync,
    save_upload_limited,
)

# --- LLM + similarity helpers ---
import httpx
import json
import difflib
import uuid
import time
import requests
import math
from typing import Optional, List, Dict, Any

# Try to import sentence-transformers for better embeddings-based similarity if available
try:
    from sentence_transformers import SentenceTransformer
    _ST_MODEL = SentenceTransformer("all-MiniLM-L6-v2")
except Exception:
    _ST_MODEL = None

# Import Hugging Face utilities for local AI processing
try:
    from huggingface_utils import (
        evaluate_answer_hybrid,
        generate_question_hybrid,
        preload_models,
        get_semantic_similarity,
        evaluate_answer_comprehensive,
        transcribe_audio as hf_transcribe_audio,
        get_model_info
    )
    HF_AVAILABLE = True
    print("‚úÖ Hugging Face utilities loaded successfully")
except Exception as e:
    HF_AVAILABLE = False
    print(f"‚ö†Ô∏è  Hugging Face utilities not available: {e}")

# Import AI detection heuristics
try:
    from ai_detection import detect_ai_generated, get_detailed_report
    AI_DETECTION_AVAILABLE = True
    print("‚úÖ AI detection heuristics loaded successfully")
except Exception as e:
    AI_DETECTION_AVAILABLE = False
    print(f"‚ö†Ô∏è  AI detection not available: {e}")

# Import smart question generator
try:
    from question_generator import generate_smart_questions, get_category_context
    SMART_GENERATOR_AVAILABLE = True
    print("‚úÖ Smart question generator loaded successfully")
except Exception as e:
    SMART_GENERATOR_AVAILABLE = False
    print(f"‚ö†Ô∏è  Smart question generator not available: {e}")


from fastapi import (
    FastAPI, Request, Form, UploadFile, File, Depends, BackgroundTasks, HTTPException, Body, WebSocket, WebSocketDisconnect)

from fastapi.responses import HTMLResponse, JSONResponse, RedirectResponse, Response, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from starlette.middleware.sessions import SessionMiddleware
from itsdangerous import URLSafeTimedSerializer, BadSignature, SignatureExpired
from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Text, ForeignKey
from sqlalchemy.orm import sessionmaker, declarative_base, relationship, scoped_session
# passlib hashers: prefer Argon2, but keep bcrypt as legacy fallback
from passlib.hash import argon2, bcrypt
PREFERRED_HASHER = argon2   # new accounts and resets use Argon2
LEGACY_HASHER = bcrypt      # fallback for existing bcrypt hashes
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.units import inch
from gtts import gTTS
from textblob import TextBlob
try:
    import language_tool_python
    LANGUAGE_TOOL_AVAILABLE = True
except ImportError:
    LANGUAGE_TOOL_AVAILABLE = False
    print("‚ö†Ô∏è  language_tool_python not available (grammar checking disabled)")
import librosa
import numpy as np

# Removed conflicting imports that duplicated definitions in this file:
# from models import Question, Attempt
# from database import get_db


# after imports at top of fastapi_app.py
import os

# Try to ensure MoviePy / imageio find the ffmpeg binary
try:
    import imageio_ffmpeg as _i4
    ffmpeg_exe = _i4.get_ffmpeg_exe()
    if ffmpeg_exe:
        os.environ["IMAGEIO_FFMPEG_EXE"] = ffmpeg_exe
        # also set MoviePy config if available
        try:
            import moviepy.config as mp_conf
            mp_conf.change_settings({"FFMPEG_BINARY": ffmpeg_exe})
        except Exception:
            pass
        print("Using ffmpeg at:", ffmpeg_exe)
except Exception:
    # not critical ‚Äî system ffmpeg should still work
    pass



# Initialize language tool if available
try:
    if LANGUAGE_TOOL_AVAILABLE:
        import language_tool_python
        tool = language_tool_python.LanguageTool('en-US')
    else:
        tool = None
except Exception:
    tool = None
    LANGUAGE_TOOL_AVAILABLE = False

# ---------------------------
# Config
# ---------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# keep your original TEMPLATES_DIR variable, but fall back to BASE_DIR if templates/ missing
TEMPLATES_DIR = os.path.join(BASE_DIR, "templates")
if not os.path.isdir(TEMPLATES_DIR):
    # fall back to project root where your uploaded HTML files live
    TEMPLATES_DIR = BASE_DIR

STATIC_DIR = os.path.join(BASE_DIR, "static")
os.makedirs(STATIC_DIR, exist_ok=True)

# Top companies for interview preparation
COMPANIES = [
    "Google",
    "Amazon",
    "Microsoft",
    "Meta (Facebook)",
    "Apple",
    "NVIDIA",
    "Twitter (X)",
    "IBM",
    "Oracle"
]

DB_PATH = os.path.join(BASE_DIR, "database.db")
# Use DATABASE_URL from environment, fallback to SQLite for development
DATABASE_URL = os.environ.get("DATABASE_URL", f"sqlite:///{DB_PATH}")

SECRET_KEY = os.environ.get("SECRET_KEY", "dev-only-change-in-production")
MAIL_USERNAME = os.environ.get("MAIL_USERNAME")
MAIL_PASSWORD = os.environ.get("MAIL_PASSWORD")
UPLOAD_FOLDER = os.path.join(STATIC_DIR, "audio")
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Token serializer (password reset)
serializer = URLSafeTimedSerializer(SECRET_KEY)

# ---------------------------
# FastAPI app + templates
# ---------------------------
app = FastAPI()
# secure Session middleware for cookie-based sessions
from starlette.middleware.sessions import SessionMiddleware

# Ensure you have SECRET_KEY set (in env or a config area)
try:
    SECRET_KEY = SECRET_KEY  # if already defined in file from env
except NameError:
    SECRET_KEY = "change_this_secret_for_prod"  # replace in .env/production

app.add_middleware(
    SessionMiddleware,
    secret_key=SECRET_KEY,
    https_only=False,   # Set to True only in production with HTTPS
    max_age=86400,      # 1 day
    same_site="lax",    # "lax" for better mobile compatibility
)

app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")
templates = Jinja2Templates(directory=TEMPLATES_DIR)

# Include OAuth and auth routes
from auth_routes import router as auth_router
app.include_router(auth_router)

# ---------------------------
# Database (SQLAlchemy)
# ---------------------------
# Database engine configuration with connection pooling
if DATABASE_URL.startswith("sqlite"):
    connect_args = {"check_same_thread": False}
    engine = create_engine(DATABASE_URL, connect_args=connect_args)
else:
    # PostgreSQL/Supabase with proper pooling
    engine = create_engine(
        DATABASE_URL,
        pool_size=5,
        max_overflow=10,
        pool_pre_ping=True,  # Verify connections before using
        pool_recycle=3600,   # Recycle connections after 1 hour
        echo=False
    )
SessionLocal = scoped_session(sessionmaker(autocommit=False, autoflush=False, bind=engine))
Base = declarative_base()


# ---------------------------
# Models (mirror your Flask models)
# ---------------------------
class User(Base):
    __tablename__ = "user"
    id = Column(Integer, primary_key=True)
    name = Column(String(100), nullable=False)
    email = Column(String(100), unique=True, nullable=False)
    password = Column(String(200), nullable=False)
    total_score = Column(Float, default=0.0)
    attempts = Column(Integer, default=0)
    badge = Column(String(100), default="üéØ Rising Learner")

    attempts_list = relationship("Attempt", back_populates="user", cascade="all, delete-orphan")
    saved_questions = relationship("SavedQuestion", back_populates="user", cascade="all, delete-orphan")


class Attempt(Base):
    __tablename__ = "attempt"
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey("user.id"), nullable=False)
    question = Column(String(500))
    score = Column(Float)
    feedback = Column(Text)
    timestamp = Column(DateTime, default=datetime.utcnow)

    user = relationship("User", back_populates="attempts_list")


class SavedQuestion(Base):
    __tablename__ = "saved_question"
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey("user.id"), nullable=False)
    question = Column(String(500), nullable=False)
    company = Column(String(100), nullable=True)  # Company tag (Google, Amazon, etc.)
    timestamp = Column(DateTime, default=datetime.utcnow)

    user = relationship("User", back_populates="saved_questions")



Base.metadata.create_all(bind=engine)

# ---------------------------
# Utility: DB Session dependency
# ---------------------------
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# ---------------------------
# Emulate flask login / session
# ---------------------------
def get_current_user(request: Request, db):
    """Get current logged-in user from session"""
    uid = request.session.get("user_id")
    if not uid:
        return None
    u = db.query(User).filter_by(id=uid).first()
    return u

def require_user(request: Request, db):
    """Require user to be logged in, raise exception if not"""
    user = get_current_user(request, db)
    if not user:
        raise HTTPException(status_code=303, detail="Login required")
    return user


# ------------------ Dynamic question bank (internet-backed) ------------------
import requests
from time import time
from sklearn.feature_extraction.text import TfidfVectorizer
from math import ceil

# A small local fallback bank (kept for offline dev/testing)
LOCAL_QUESTION_BANK = {
    "Python": [
        "What are Python decorators?",
        "Explain list comprehensions in Python.",
        "What is the difference between deep and shallow copy?",
        "What are Python generators and when would you use them?",
        "Explain OOP (classes, inheritance) in Python."
    ],
    "Web Development": [
        "What is REST API and how does it work?",
        "Explain the difference between frontend and backend.",
        "What is the role of JavaScript in modern web apps?",
        "What is Flask and how does it work?"
    ],
    "Data Structures": [
        "What's the difference between a stack and a queue?",
        "Explain Big O notation with examples.",
        "How does a linked list differ from an array?"
    ],
    "HR / Behavioral": [
        "Tell me about yourself.",
        "Why do you want this job?",
        "What are your strengths?",
        "Describe a time you failed and what you learned."
    ],
    "System Design": [
        "How would you design a URL shortener?",
        "What is load balancing and why is it used?",
        "Explain caching strategies in system design."
    ],
    "AI / ML": [
        "What is supervised learning?",
        "Explain overfitting and how to prevent it.",
        "What is the difference between classification and regression?"
    ]
}

# Initialize app state on startup
@app.on_event("startup")
async def startup_event():
    """Initialize application state and caches on startup"""
    if not hasattr(app.state, "question_bank"):
        app.state.question_bank = {k: list(v) for k, v in LOCAL_QUESTION_BANK.items()}
    if not hasattr(app.state, "generated_questions"):
        app.state.generated_questions = {}
    if not hasattr(app.state, "copyleaks_token_cache"):
        app.state.copyleaks_token_cache = {"token": None, "expires_at": 0}
    if not hasattr(app.state, "copyleaks_pending"):
        app.state.copyleaks_pending = {}
    if not hasattr(app.state, "copyleaks_results"):
        app.state.copyleaks_results = {}
    
    # Preload Hugging Face models for faster first requests
    if HF_AVAILABLE:
        try:
            print("ü§ó Preloading Hugging Face models...")
            preload_models()
        except Exception as e:
            print(f"‚ö†Ô∏è  Hugging Face model preload failed: {e}")
    
    print("‚úÖ Application startup complete - caches initialized")

# ---------------------- Compatibility helpers ----------------------
# Ensure the dynamic question bank exists (defensive)
if not hasattr(app.state, "question_bank"):
    try:
        app.state.question_bank = {k: list(v) for k, v in LOCAL_QUESTION_BANK.items()}
    except Exception:
        app.state.question_bank = {}

# Provide a module-level current category + current_question for backwards-compatibility
# (some parts of the app expect `current_question` to exist as a dict with a "q" key).
import random as _random

# default category
current_category = "Python"

def get_current_question_obj(category: str = None):
    """
    Return a dict-like current_question: {'q': <question string>, 'keywords': []}
    This avoids NameError and centralizes sourcing from app.state.question_bank.
    """
    cat = (category or current_category) or "Python"
    bank = app.state.question_bank.get(cat) if hasattr(app.state, "question_bank") else None
    # if bank is empty, use LOCAL_QUESTION_BANK as last resort
    if not bank:
        bank = LOCAL_QUESTION_BANK.get(cat) or sum(LOCAL_QUESTION_BANK.values(), [])
    # choose a random question safely
    if bank:
        qtext = bank[_random.randrange(len(bank))] if len(bank) > 1 else bank[0]
    else:
        qtext = "Explain a programming concept you're comfortable with."
    return {"q": qtext, "keywords": []}

# initialize module-level current_question used by older code paths
try:
    current_question = get_current_question_obj(current_category)
except Exception:
    current_question = {"q": "Explain a programming concept you're comfortable with.", "keywords": []}

def refresh_current_question(new_category: str = None):
    """
    Call this when you change category or after you generate new questions.
    It updates the module-level current_question and current_category.
    """
    global current_category, current_question
    if new_category:
        current_category = new_category
    current_question = get_current_question_obj(current_category)
    return current_question

def _ensure_current_question_obj():
    """
    Return a dict-like current_question object: {'q': <text>, 'keywords': [...]}
    This will convert legacy string values to dicts and always provide a safe structure.
    """
    global current_question, current_category
    # If module-level variable is a plain string (old code), convert to dict
    if isinstance(current_question, str):
        current_question = {"q": current_question, "keywords": []}
        return current_question
    # If it's already a dict, ensure it has keys
    if isinstance(current_question, dict):
        if "q" not in current_question:
            # try to reconstruct from category
            current_question.setdefault("q", get_current_question_obj(current_category).get("q", "Explain something."))
        if "keywords" not in current_question:
            current_question.setdefault("keywords", [])
        return current_question
    # If missing or any other type, recreate from the bank
    current_question = get_current_question_obj(current_category)
    return current_question

# ------------------ Helpers for internet generation & local similarity ------------------
SERPAPI_KEY = os.environ.get("SERPAPI_KEY")  # optional
COPYLEAKS_API_KEY = os.environ.get("COPYLEAKS_API_KEY")
COPYLEAKS_EMAIL = os.environ.get("COPYLEAKS_EMAIL")

def serpapi_search_questions(query: str, count: int = 10):
    """Use SerpAPI to fetch candidate question-like strings (optional)."""
    if not SERPAPI_KEY:
        return []
    try:
        params = {"engine": "google", "q": query, "api_key": SERPAPI_KEY, "num": count}
        r = requests.get("https://serpapi.com/search.json", params=params, timeout=8)
        j = r.json()
        items = []
        for item in j.get("organic_results", [])[:count]:
            title = item.get("title", "")
            snippet = item.get("snippet", "")
            if title.strip().endswith("?"):
                items.append(title.strip())
            else:
                combined = (title + " " + snippet).strip()
                if len(combined) > 30:
                    items.append(combined[:220])
        return items[:count]
    except Exception as e:
        print("SerpAPI search failed:", e)
        return []

async def generate_questions_from_llm(category: str, count: int = 10):
    """Use existing call_llm_chat to produce a JSON array of questions."""
    prompt_user = (f"Return a JSON array of {count} concise, distinct interview-style questions for the "
                   f"category: {category}. Keep each question short (<= 120 chars). Respond with pure JSON array.")
    resp = await call_llm_chat("You are a helpful question generator.", prompt_user, model="gpt-4o-mini", max_tokens=500)
    try:
        arr = json.loads(resp)
        if isinstance(arr, list):
            return [str(x).strip() for x in arr][:count]
    except Exception:
        lines = [l.strip("-‚Ä¢ \n\t") for l in str(resp).splitlines() if l.strip()]
        if lines:
            return lines[:count]
    return []

def shingle_similarity(a: str, b: str, k: int = 5) -> float:
    """Shingle (k-gram) Jaccard similarity fallback."""
    def shingles(s):
        s = s.lower()
        tokens = s.split()
        if len(tokens) < k:
            return set([" ".join(tokens)])
        return set(" ".join(tokens[i:i+k]) for i in range(max(0, len(tokens)-k+1)))
    s1, s2 = shingles(a), shingles(b)
    if not s1 or not s2:
        return 0.0
    inter = len(s1 & s2)
    union = len(s1 | s2)
    return inter / union if union else 0.0

def local_similarity_candidates(text: str, db=None, top_k=10):
    """
    Local similarity check against:
      - app.state.generated_questions (in-memory)
      - SavedQuestion (DB)
      - recent attempts (DB)
    Returns top_k matches sorted by similarity (0..1).
    Uses sentence-transformers if available, otherwise shingle fallback.
    """
    candidates = []
    for gid, meta in getattr(app.state, "generated_questions", {}).items():
        candidates.append(("generated", gid, meta.get("prompt", "")))
    if db is not None:
        try:
            saved_rows = db.query(SavedQuestion).all()
            for r in saved_rows:
                candidates.append(("saved_question", r.id, r.question))
            attempts = db.query(Attempt).order_by(Attempt.timestamp.desc()).limit(200).all()
            for a in attempts:
                content = getattr(a, "user_answer", None) or getattr(a, "question", "") or ""
                candidates.append(("attempt", a.id, content))
        except Exception:
            pass

    scored = []
    if _ST_MODEL is not None:
        try:
            texts = [c[2] for c in candidates if c[2]]
            if texts:
                vecs = _ST_MODEL.encode(texts, convert_to_numpy=True)
                import numpy as np
                qv = _ST_MODEL.encode([text], convert_to_numpy=True)[0]
                for idx, c in enumerate(candidates):
                    denom = (np.linalg.norm(vecs[idx]) * np.linalg.norm(qv))
                    sim = float(np.dot(vecs[idx], qv) / denom) if denom else 0.0
                    scored.append({"source": c[0], "id": c[1], "sim": sim, "excerpt": c[2][:200]})
        except Exception:
            for c in candidates:
                s = shingle_similarity(text, c[2])
                scored.append({"source": c[0], "id": c[1], "sim": s, "excerpt": c[2][:200]})
    else:
        for c in candidates:
            s = shingle_similarity(text, c[2])
            scored.append({"source": c[0], "id": c[1], "sim": s, "excerpt": c[2][:200]})

    scored.sort(key=lambda x: x["sim"], reverse=True)
    return scored[:top_k]

# ---------------------------
# Helper: flash (simple)
# ---------------------------
def add_flash(request: Request, message: str, category: str = "info"):
    flashes = request.session.setdefault("_flashes", [])
    flashes.append({"msg": message, "cat": category})
    request.session["_flashes"] = flashes

def pop_flashes(request: Request):
    return request.session.pop("_flashes", [])


# ---------------------------
# Routes (template-rendering + API)
# ---------------------------
# --- Copyleaks integration: submit / poll / webhook handler ----------------
import base64
import time
import requests
from typing import Optional

COPYLEAKS_EMAIL = os.environ.get("COPYLEAKS_EMAIL")
COPYLEAKS_API_KEY = os.environ.get("COPYLEAKS_API_KEY")
COPYLEAKS_WEBHOOK_URL = os.environ.get("COPYLEAKS_WEBHOOK_URL")  # must be public for webhooks

# app.state caches
if not hasattr(app.state, "copyleaks_token_cache"):
    app.state.copyleaks_token_cache = {"token": None, "expires_at": 0}
if not hasattr(app.state, "copyleaks_pending"):
    # map scanId -> {"status": "pending"|"completed"|"error", "meta": {...}, "result": {...}}
    app.state.copyleaks_pending = {}
if not hasattr(app.state, "copyleaks_results"):
    app.state.copyleaks_results = {}

COPYLEAKS_AUTH_URL = "https://id.copyleaks.com/v3/account/login/api"
COPYLEAKS_SUBMIT_FILE_URL = "https://api.copyleaks.com/v3/scans/submit/file/{scanId}"
COPYLEAKS_GET_SCAN_URL = "https://api.copyleaks.com/v3/scans/{scanId}"  # used for quick status checks
COPYLEAKS_EXPORT_URL = "https://api.copyleaks.com/v3/downloads/{scanId}/export/{exportId}"


def get_copyleaks_token(force_refresh: bool = False, ttl_margin: int = 30) -> Optional[str]:
    """
    Acquire a temporary login token from Copyleaks using email + API key.
    Tokens are cached in app.state.copyleaks_token_cache until expiry.
    See docs: https://docs.copyleaks.com/reference/actions/account/login/ . :contentReference[oaicite:5]{index=5}
    """
    cache = app.state.copyleaks_token_cache
    now = int(time.time())
    if not force_refresh and cache.get("token") and cache.get("expires_at", 0) - ttl_margin > now:
        return cache["token"]
    if not (COPYLEAKS_EMAIL and COPYLEAKS_API_KEY):
        return None
    try:
        payload = {"email": COPYLEAKS_EMAIL, "key": COPYLEAKS_API_KEY}
        r = requests.post(COPYLEAKS_AUTH_URL, json=payload, timeout=12)
        r.raise_for_status()
        j = r.json()
        # Copyleaks returns access token and expiry; doc says token is valid for ~48h.
        token = j.get("access_token") or j.get("token") or j.get("login_token") or j.get("token")  # defensive
        expires = now + int(j.get("expires_in", 60 * 60 * 48)) if j.get("expires_in") else now + 60 * 60 * 48
        cache["token"] = token
        cache["expires_at"] = expires
        return token
    except Exception as e:
        print("Copyleaks: token request failed:", e)
        return None


def submit_text_to_copyleaks(text: str, scan_id: Optional[str] = None, webhook_url: Optional[str] = None) -> dict:
    """
    Submit TEXT as a .txt file to Copyleaks. Returns dict with {scan_id, accepted, detail}
    Copyleaks expects file content base64-encoded using the 'submit/file' endpoint. :contentReference[oaicite:6]{index=6}
    The API is asynchronous: Copyleaks will call your webhook when scan completes. :contentReference[oaicite:7]{index=7}
    """
    if not COPYLEAKS_API_KEY or not COPYLEAKS_EMAIL:
        return {"accepted": False, "error": "Copyleaks credentials not configured."}
    tok = get_copyleaks_token()
    if not tok:
        return {"accepted": False, "error": "Could not get Copyleaks token."}

    if not scan_id:
        scan_id = (str(uuid.uuid4())[:36]).replace("-", "")[:36]  # Copyleaks recommends 3-36 chars
    url = COPYLEAKS_SUBMIT_FILE_URL.format(scanId=scan_id)

    # base64-encoded text (use proper base64, not hex)
    b64 = base64.b64encode(text.encode("utf-8")).decode("utf-8")
    data = {
        "base64": b64,
        "filename": "submission.txt",
        "properties": {
            # If caller provided webhook_url, use it; else try configured env value
            "webhooks": [webhook_url or COPYLEAKS_WEBHOOK_URL] if (webhook_url or COPYLEAKS_WEBHOOK_URL) else []
        }
    }
    headers = {"Authorization": f"Bearer {tok}", "Content-Type": "application/json"}
    try:
        r = requests.put(url, json=data, headers=headers, timeout=20)
        # 200/201/202 expected for accepted submissions
        if r.status_code in (200, 201, 202):
            app.state.copyleaks_pending[scan_id] = {"status": "pending", "submitted_at": time(), "text_excerpt": text[:200]}
            return {"accepted": True, "scan_id": scan_id, "status_code": r.status_code, "body": r.json() if r.content else {}}
        else:
            return {"accepted": False, "scan_id": scan_id, "status_code": r.status_code, "body": r.text}
    except Exception as e:
        return {"accepted": False, "scan_id": scan_id, "error": str(e)}


def quick_poll_scan_status(scan_id: str, timeout_sec: int = 12, interval: float = 2.0) -> dict:
    """
    Try to poll scan status briefly. Most Copyleaks flows use webhooks and are asynchronous;
    this helper attempts a short poll for convenience. If not ready, returns {'ready':False}.
    """
    tok = get_copyleaks_token()
    if not tok:
        return {"ready": False, "error": "no token"}
    end = time.time() + timeout_sec
    headers = {"Authorization": f"Bearer {tok}"}
    status_url = COPYLEAKS_GET_SCAN_URL.format(scanId=scan_id)
    while time.time() < end:
        try:
            r = requests.get(status_url, headers=headers, timeout=8)
            if r.status_code == 200:
                j = r.json()
                # docs: check for status in the JSON (completed/processing/failed etc.)
                # We'll store the whole JSON as result when completed
                s = j.get("status") or j.get("scanStatus") or j
                if isinstance(s, str) and s.lower() in ("completed", "done", "success"):
                    app.state.copyleaks_pending[scan_id] = {"status": "completed", "raw": j}
                    app.state.copyleaks_results[scan_id] = j
                    return {"ready": True, "result": j}
                # if not completed, continue polling
            elif r.status_code == 404:
                return {"ready": False, "error": "scan not found"}
        except Exception as e:
            # network glitch ‚Äî keep trying until timeout
            pass
        time.sleep(interval)
    # timed out
    return {"ready": False}


# API endpoint helper: submit and attempt short poll (useful for your /plagiarism_check endpoint)
@app.post("/copyleaks/submit_text_for_scan")
def copyleaks_submit_text(payload: dict = None):
    data = payload or {}
    text = (data.get("text") or "").strip()
    if not text:
        return JSONResponse({"error": "empty text"}, status_code=400)
    # optional scan_id provided by caller
    scan_id = data.get("scan_id") or None
    # optional webhook_url override
    webhook_url = data.get("webhook_url") or None

    res = submit_text_to_copyleaks(text, scan_id=scan_id, webhook_url=webhook_url)
    if not res.get("accepted"):
        return JSONResponse({"accepted": False, "detail": res}, status_code=500)
    # try a quick poll for immediate result (not guaranteed)
    scan_id = res.get("scan_id")
    poll = quick_poll_scan_status(scan_id, timeout_sec=10, interval=2.0)
    response_payload = {"accepted": True, "scan_id": scan_id, "poll": poll}
    # If poll returned result, attach it; else instruct caller to wait for webhook
    if poll.get("ready"):
        response_payload["result"] = poll["result"]
    else:
        response_payload["notice"] = "Submitted to Copyleaks. Result will be posted to your webhook when completed. You may poll status or use the webhook."
    return JSONResponse(response_payload)


# Webhook receiver: accept Copyleaks webhooks and persist them in-memory (and to DB as needed)
# Copyleaks will call endpoints like /copyleaks/webhook/completed/{scanId} ‚Äî we provide a generic handler.
@app.post("/copyleaks/webhook/{status}/{scan_id}")
async def copyleaks_webhook(status: str, scan_id: str, request: Request):
    """
    Generic webhook handler. Copyleaks will POST JSON payloads describing the scan event.
    Recommended webhook URL pattern: https://yourserver.com/copyleaks/webhook/{status}/{scanId}
    Docs: https://docs.copyleaks.com/reference/data-types/authenticity/webhooks/overview/ . :contentReference[oaicite:8]{index=8}
    """
    body = await request.json()
    # store webhook payload in memory so UI / API can pick it up
    app.state.copyleaks_pending[scan_id] = {"status": status, "hook_payload": body, "received_at": time()}
    # optionally, immediately fetch exports (AI detection/result ids) if available in payload
    # Many Copyleaks webhooks include "resultIds" you can export; you can call the export endpoint with the login token.
    # We'll stash the webhook body and let a background job or manual caller fetch exports.
    app.state.copyleaks_results[scan_id] = {"status": status, "payload": body}
    # IMPORTANT: reply 200 quickly ‚Äî Copyleaks expects 200 OK for deliver confirmation.
    return JSONResponse({"ok": True, "scan_id": scan_id, "status": status})
# ---------------- HEALTH CHECK ----------------
@app.get("/health")
def health_check():
    """Health check endpoint for monitoring and load balancers"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0",
        "huggingface_available": HF_AVAILABLE
    }


# ---------------- SESSION DEBUG (Remove in production) ----------------
@app.get("/api/session/check")
def check_session(request: Request, db=Depends(get_db)):
    """Debug endpoint to check session status"""
    user_id = request.session.get("user_id")
    user_agent = request.headers.get('user-agent', 'unknown')
    is_mobile = any(x in user_agent.lower() for x in ['mobile', 'android', 'iphone', 'ipad'])
    
    return {
        "session_exists": bool(request.session),
        "user_id": user_id,
        "logged_in": request.session.get("logged_in", False),
        "is_mobile": is_mobile,
        "user_agent": user_agent[:100],
        "session_keys": list(request.session.keys()),
        "cookies": list(request.cookies.keys())
    }


# ---------------- HUGGING FACE INFO ----------------
@app.get("/api/companies")
def get_companies():
    """Get list of companies for filtering"""
    return JSONResponse({"companies": COMPANIES})


@app.get("/api/models/info")
def get_models_info():
    """Get information about loaded Hugging Face models"""
    if not HF_AVAILABLE:
        return JSONResponse({
            "available": False,
            "message": "Hugging Face utilities not loaded"
        })
    
    try:
        info = get_model_info()
        info["available"] = True
        return JSONResponse(info)
    except Exception as e:
        return JSONResponse({
            "available": True,
            "error": str(e)
        }, status_code=500)


@app.post("/api/evaluate/local")
def evaluate_local(payload: dict):
    """Evaluate answer using only Hugging Face (no OpenAI)"""
    if not HF_AVAILABLE:
        return JSONResponse({
            "error": "Hugging Face not available"
        }, status_code=503)
    
    try:
        question = payload.get("question", "")
        answer = payload.get("answer", "")
        keywords = payload.get("keywords", [])
        
        if not answer:
            return JSONResponse({"error": "Answer required"}, status_code=400)
        
        result = evaluate_answer_comprehensive(
            question=question,
            answer=answer,
            expected_keywords=keywords
        )
        result["source"] = "huggingface_only"
        return JSONResponse(result)
    except Exception as e:
        return JSONResponse({
            "error": str(e)
        }, status_code=500)


# ---------------- PWA ROUTES ----------------
@app.get("/manifest.json")
async def get_manifest():
    """Serve PWA manifest"""
    from fastapi.responses import FileResponse
    return FileResponse("static/manifest.json", media_type="application/json")

@app.get("/sw.js")
async def get_service_worker():
    """Serve service worker"""
    from fastapi.responses import FileResponse
    return FileResponse("static/sw.js", media_type="application/javascript")

@app.get("/offline.html")
async def get_offline():
    """Serve offline page"""
    from fastapi.responses import FileResponse
    return FileResponse("static/offline.html", media_type="text/html")


# ---------------- HOME ----------------
@app.get("/", response_class=HTMLResponse)
def home(request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse(url="/login")
    # ensure current_question is an object
    cq = _ensure_current_question_obj()
    q = cq.get("q") if isinstance(cq, dict) else str(cq)
    return templates.TemplateResponse("index.html", {"request": request, "question": q, "user": user})



# ---------------- REGISTER ----------------
@app.get("/register", response_class=HTMLResponse)
def register_get(request: Request):
    return templates.TemplateResponse("register.html", {"request": request})

def validate_password_strength(password: str) -> tuple[bool, str]:
    """
    Validate password strength with comprehensive checks.
    Returns (is_valid, error_message)
    """
    if len(password) < 8:
        return False, "Password must be at least 8 characters long"
    
    if not any(c.isupper() for c in password):
        return False, "Password must contain at least one uppercase letter"
    
    if not any(c.islower() for c in password):
        return False, "Password must contain at least one lowercase letter"
    
    if not any(c.isdigit() for c in password):
        return False, "Password must contain at least one number"
    
    if not any(c in "!@#$%^&*(),.?\":{}|<>" for c in password):
        return False, "Password must contain at least one special character (!@#$%^&*)"
    
    return True, ""


@app.post("/register")
def register_post(request: Request,
                  name: str = Form(...),
                  email: str = Form(...),
                  password: str = Form(...),
                  confirm_password: str = Form(None),
                  db=Depends(get_db)):
    name = name.strip()
    email = email.strip().lower()
    
    # Validate all fields
    if not name or not email or not password:
        add_flash(request, "Please fill all fields", "danger")
        return RedirectResponse("/login", status_code=303)
    
    # Validate name length
    if len(name) < 2:
        add_flash(request, "Name must be at least 2 characters long", "danger")
        return RedirectResponse("/login", status_code=303)
    
    # Validate email format
    import re
    email_regex = r'^[^\s@]+@[^\s@]+\.[^\s@]+$'
    if not re.match(email_regex, email):
        add_flash(request, "Please enter a valid email address", "danger")
        return RedirectResponse("/login", status_code=303)
    
    # Check if email already exists
    if db.query(User).filter_by(email=email).first():
        add_flash(request, "Email already registered! Please login instead.", "danger")
        return RedirectResponse("/login", status_code=303)
    
    # Validate password strength
    is_valid, error_msg = validate_password_strength(password)
    if not is_valid:
        add_flash(request, error_msg, "danger")
        return RedirectResponse("/login", status_code=303)
    
    # Validate password confirmation if provided
    if confirm_password and password != confirm_password:
        add_flash(request, "Passwords do not match", "danger")
        return RedirectResponse("/login", status_code=303)
    
    # Create new user
    hashed = get_password_hash(password)
    new_user = User(name=name, email=email, password=hashed)
    db.add(new_user)
    db.commit()
    
    add_flash(request, "Registration successful! Please log in.", "success")
    return RedirectResponse("/login", status_code=303)


# ---------------- LOGIN ----------------
@app.get("/login", response_class=HTMLResponse)
def login_get(request: Request):
    flashes = pop_flashes(request)
    return templates.TemplateResponse("login.html", {"request": request, "flashes": flashes})

@app.get("/login_test", response_class=HTMLResponse)
def login_test_get(request: Request):
    """Simple login test page for debugging"""
    flashes = pop_flashes(request)
    return templates.TemplateResponse("login_test.html", {"request": request, "flashes": flashes})

def verify_and_migrate_password(candidate_pw: str, user_obj, db):
    """
    Verify candidate_pw against stored hash (user_obj.password).
    - Try Argon2 (preferred) first.
    - If Argon2 verification fails, try legacy bcrypt.
      If bcrypt verifies, re-hash using Argon2 and persist (automatic migration).
    Returns True on success, False otherwise.
    """
    stored_hash = getattr(user_obj, "password", None)
    if not stored_hash:
        return False

    # Try preferred hasher (Argon2)
    try:
        if PREFERRED_HASHER.verify(candidate_pw, stored_hash):
            return True
    except Exception:
        # ignore and continue to legacy check
        pass

    # Fallback to legacy (bcrypt)
    try:
        if LEGACY_HASHER.verify(candidate_pw, stored_hash):
            # attempt to migrate to Argon2 (non-blocking if it fails)
            try:
                user_obj.password = PREFERRED_HASHER.hash(candidate_pw)
                db.add(user_obj)
                db.commit()
            except Exception:
                try:
                    db.rollback()
                except Exception:
                    pass
            return True
    except Exception:
        pass

    return False

# safe redirect helper ‚Äî add near other utility functions
from urllib.parse import urlparse

def is_safe_redirect(target: str) -> bool:
    """
    Allow only relative paths (no network location) to avoid open redirect.
    Use this to validate 'next' query/form params before redirecting.
    """
    if not target:
        return False
    p = urlparse(target)
    # only allow relative URLs (no scheme, no netloc)
    return p.scheme == "" and p.netloc == ""


@app.post("/login")
async def login_post(request: Request,
               email: str = Form(...),
               password: str = Form(...),
               next: str = Form(None),
               db=Depends(get_db)):
    """
    Login handler with enhanced mobile support.
    Optional `next` form field accepted and validated by is_safe_redirect.
    """
    try:
        email = email.strip().lower()
        
        # Log attempt for debugging
        user_agent = request.headers.get('user-agent', 'unknown')
        is_mobile = any(x in user_agent.lower() for x in ['mobile', 'android', 'iphone', 'ipad'])
        print(f"üîê Login attempt: {email}, Mobile: {is_mobile}")
        
        user = db.query(User).filter_by(email=email).first()

        # verify password
        if user and verify_and_migrate_password(password, user, db):
            # Set session data
            request.session["user_id"] = user.id
            request.session["logged_in"] = True
            
            add_flash(request, "Login successful!", "success")
            
            print(f"‚úÖ Login successful for {email}, user_id: {user.id}")

            # If a safe next URL was provided, redirect there; otherwise redirect home
            if next and is_safe_redirect(next):
                return RedirectResponse(next, status_code=303)
            return RedirectResponse("/", status_code=303)

        print(f"Login failed for {email}: Invalid credentials")
        add_flash(request, "Invalid email or password.", "danger")
        return RedirectResponse("/login", status_code=303)
        
    except Exception as e:
        print(f"Login error: {e}")
        add_flash(request, "Login error. Please try again.", "danger")
        return RedirectResponse("/login", status_code=303)

# ---------------- LOGIN END ----------------


# ---------------- LOGOUT ----------------
@app.get("/logout")
def logout(request: Request):
    request.session.clear()
    add_flash(request, "Logged out successfully.", "info")
    return RedirectResponse("/login", status_code=303)


# ---------------- PRACTICE ----------------
@app.get("/practice", response_class=HTMLResponse)
def practice(request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")

    # Pull categories from dynamic bank (fallback to local)
    categories = list(app.state.question_bank.keys()) if hasattr(app.state, "question_bank") else list(LOCAL_QUESTION_BANK.keys())
    # Ensure a current question object
    cq = _ensure_current_question_obj()
    q_text = cq.get("q") if isinstance(cq, dict) else str(cq)

    return templates.TemplateResponse(
        "practice.html",
        {
            "request": request,
            "user": user,
            "question": q_text,
            "categories": categories,
            "companies": COMPANIES,  # Add companies list
        },
    )

# ---------------- MOCK INTERVIEW ----------------
@app.get("/mock_interview", response_class=HTMLResponse)
def mock_interview(request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")

    # try to pull auto-generated questions for chosen categories
    # If none available, we will generate 5 via generate_questions endpoint (LLM/SerpAPI)
    total = 5

    if not request.session.get("mock_questions"):
        # generate synchronous-ish fallback by calling generator endpoint via internal call
        # (we call the coroutine for generate_questions if available)
        import asyncio
        import json as _json

        try:
            coro = generate_questions({"category": "General", "count": total})

            # Try to run coroutine on current loop; if loop is running, create a new loop
            try:
                js_resp = asyncio.get_event_loop().run_until_complete(coro)
            except RuntimeError:
                # event loop already running (safety) -> create a new temporary loop
                new_loop = asyncio.new_event_loop()
                try:
                    asyncio.set_event_loop(new_loop)
                    js_resp = new_loop.run_until_complete(coro)
                finally:
                    # restore default policy (don't leave a running loop set)
                    try:
                        new_loop.close()
                    except Exception:
                        pass
                    asyncio.set_event_loop(None)

            # if JSONResponse, extract its body; if dict/list, use directly
            created_json = None
            if hasattr(js_resp, "body"):
                try:
                    created_json = _json.loads(js_resp.body.decode())
                except Exception:
                    created_json = None

            if created_json is None and isinstance(js_resp, (dict, list)):
                created_json = js_resp

            # now extract created prompts safely
            try:
                created_list = created_json.get("created", []) if isinstance(created_json, dict) else created_json
                questions = [c.get("prompt") if isinstance(c, dict) else str(c) for c in created_list][:total]
                if not questions:
                    raise Exception("No questions returned")
            except Exception:
                questions = [q for q in LOCAL_QUESTION_BANK.get("Python", [])][:total]

        except Exception:
            # last-resort fallback
            questions = [q for q in LOCAL_QUESTION_BANK.get("Python", [])][:total]

        request.session["mock_questions"] = questions

    session_questions = request.session["mock_questions"]
    request.session["mock_index"] = 0
    
    # Get top learners from database
    top_learners = []
    try:
        all_users = db.query(User).all()
        for u in all_users:
            if u.attempts > 0:
                avg = round(u.total_score / u.attempts, 1)
                top_learners.append({"name": u.name, "avg": avg})
        top_learners = sorted(top_learners, key=lambda x: x["avg"], reverse=True)[:3]
    except Exception:
        top_learners = []
    
    return templates.TemplateResponse(
        "mock_interview.html",
        {"request": request, "user": user, "total": len(session_questions), "top_learners": top_learners}
    )

@app.get("/get_mock_question")
async def get_mock_question(index: int = 0, request: Request = None):
    """
    Returns a question - tries AI-generated questions from session first, then falls back.
    """
    try:
        # Get category from session if available
        category = "General"
        if request and hasattr(request, 'session'):
            category = request.session.get("current_category", "General")
            
            # Try to get from category-specific AI-generated questions
            category_questions = request.session.get("category_questions", [])
            if category_questions:
                # Cycle through questions
                q_index = index % len(category_questions)
                question = category_questions[q_index]
                # Update index for next call
                request.session["question_index"] = (q_index + 1) % len(category_questions)
                return {"question": question, "ai_generated": True}
            
            # Try to get from mock interview questions
            mock_questions = request.session.get("mock_questions", [])
            if mock_questions and index < len(mock_questions):
                q = mock_questions[index]
                if isinstance(q, dict):
                    return {"question": q.get("prompt", str(q)), "ai_generated": True}
                return {"question": str(q), "ai_generated": True}
        
        # Generate a new AI question on-the-fly
        try:
            from llm_utils import call_llm_chat
            system_prompt = "You are an expert interview question generator. Generate ONE concise, professional interview question."
            user_prompt = f"Generate a single interview question for the category: '{category}'. Return ONLY the question text, nothing else."
            
            question_text = await call_llm_chat(system_prompt, user_prompt, temperature=0.7, max_tokens=100)
            question_text = question_text.strip().strip('"').strip("'").strip('`')
            
            if question_text and len(question_text) > 10:
                return {"question": question_text, "ai_generated": True}
        except Exception as e:
            print(f"‚ö†Ô∏è AI question generation failed: {e}")
        
        # Fallback to dynamic question bank
        qbank = getattr(app.state, "question_bank", None)
        if qbank:
            all_questions = []
            for k, v in qbank.items():
                all_questions.extend(v)
            if all_questions:
                q = all_questions[index % len(all_questions)]
                return {"question": q, "ai_generated": False}

        # Fallback to local static question list
        if "LOCAL_QUESTION_BANK" in globals():
            flat = sum(LOCAL_QUESTION_BANK.values(), [])
            if flat:
                q = flat[index % len(flat)]
                return {"question": q, "ai_generated": False}

        # Last resort
        return {"question": f"Explain a key concept or skill related to {category}.", "ai_generated": False}
    except Exception as e:
        print("‚ö†Ô∏è get_mock_question error:", e)
        return {"question": "Describe your strengths and how they relate to this role.", "ai_generated": False}


# ---------------- CHAT + FEEDBACK ----------------
def generate_tts_sync(text: str, filename: str):
    path = os.path.join(UPLOAD_FOLDER, filename)
    try:
        gTTS(text=text, lang="en").save(path)
    except Exception as e:
        print("TTS failed:", e)
        # ignore


@app.post("/chat")
def chat(request: Request, payload: dict = Body(...)):
    """
    Evaluates user's answer and returns structured feedback + score.
    """
    message = payload.get("message", "").strip()
    if not message:
        return {"reply": "Please provide an answer.", "score": 0}

    try:
        # Simulated AI scoring logic ‚Äî deterministic and always valid JSON
        word_count = len(message.split())
        score = min(10, max(1, word_count // 3))
        feedback = (
            "‚úÖ Great answer! Well structured and clear."
            if score >= 7
            else "üí° Try adding more explanation or examples."
        )

        result = {
            "reply": feedback,
            "score": score,
            "summary": "Automatic evaluation complete.",
            "improvements": [
                "Speak clearly and confidently.",
                "Add more context where possible.",
                "Keep answers concise and relevant."
            ]
        }
        return result
    except Exception as e:
        print("‚ö†Ô∏è Chat error:", e)
        return {"reply": f"Error evaluating: {str(e)}", "score": 0}


# ---------------- LLM generation / evaluation / plagiarism endpoints ----------------

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
OPENAI_CHAT_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_EMBED_URL = "https://api.openai.com/v1/embeddings"

async def call_llm_chat(system_prompt: str, user_message: str, model="gpt-4o-mini", max_tokens=400, temperature=0.2):
    """
    Async LLM call using OpenAI-style API if OPENAI_API_KEY is present.
    If no API key, returns a simple heuristic response.
    """
    if not OPENAI_API_KEY:
        # fallback: simple canned guidance (keeps app functional without an API key)
        summary = "No LLM key configured ‚Äî running lightweight local evaluation."
        improvements = [
            "Split long sentences into shorter ones.",
            "Avoid filler words; practice concise structure.",
            "Add specific technical keywords relevant to the question."
        ]
        score = round(max(3.0, min(8.0, random.uniform(4.0, 7.5))), 1)
        return json.dumps({"summary": summary, "improvements": improvements, "grammar": "", "fillers": "", "score": score})

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ],
        "max_tokens": max_tokens,
        "temperature": temperature,
    }
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            r = await client.post(OPENAI_CHAT_URL, json=payload, headers=headers)
            r.raise_for_status()
            j = r.json()
            # return assistant content or raw json if structured
            return j["choices"][0]["message"]["content"]
    except Exception as e:
        # fallback message
        return json.dumps({"summary": "LLM call failed: " + str(e), "improvements": [], "grammar": "", "fillers": "", "score": None})

def text_similarity(a: str, b: str) -> float:
    """
    Return a similarity score in [0.0, 1.0].
    If sentence-transformers available, use cosine on embeddings; otherwise use difflib ratio.
    """
    if not a or not b:
        return 0.0
    try:
        if _ST_MODEL is not None:
            vecs = _ST_MODEL.encode([a, b], convert_to_numpy=True)
            # cosine similarity
            import numpy as np
            v1, v2 = vecs[0], vecs[1]
            num = float(np.dot(v1, v2))
            denom = float(np.linalg.norm(v1) * np.linalg.norm(v2))
            if denom == 0:
                return 0.0
            return max(0.0, min(1.0, num / denom))
        else:
            # difflib fallback
            return difflib.SequenceMatcher(None, a, b).ratio()
    except Exception:
        return difflib.SequenceMatcher(None, a, b).ratio()

# Ensure we have a place to store generated questions in memory
if not hasattr(app.state, "generated_questions"):
    # map id -> { prompt, category, difficulty, created_at }
    app.state.generated_questions = {}

# replace your existing generate_questions handler with this full function
from fastapi import HTTPException
import traceback
import logging

logger = logging.getLogger("uvicorn.error")

@app.post("/generate_questions")
async def generate_questions(payload: dict):
    """
    Generate question prompts for a given category and count.
    Supports company-specific question generation.
    Always returns JSON like: {"created": [{"id": "...", "prompt":"..."}, ...]}
    """
    import os, json, asyncio, re, time
    try:
        category = (payload.get("category") or "General").strip()
        try:
            count = int(payload.get("count", 5))
        except Exception:
            count = 5
        
        # Get difficulty level (easy, medium, hard)
        difficulty = payload.get("difficulty", "medium")
        
        # Get company filter (optional)
        company = payload.get("company", "").strip()

        created = []
        t0 = time.time()
        logger.info("generate_questions called for category=%s count=%s difficulty=%s", category, count, difficulty)

        # ---------- SerpAPI block (optional) ----------
        try:
            SERPAPI_KEY = os.getenv("SERPAPI_KEY")
            if SERPAPI_KEY:
                logger.info("generate_questions: attempting SerpAPI fetch")
                # If you have a helper to fetch serp results, call it here and populate serp_results.
                serp_results = []
                # Example placeholder: serp_results = await fetch_serp_questions(category, count, SERPAPI_KEY)
                if serp_results:
                    created.extend([{"id": f"serp-{i+1}", "prompt": s} for i, s in enumerate(serp_results)])
                logger.info("generate_questions: serp results count=%s (t=%.2fs)", len(serp_results), time.time()-t0)
        except Exception as e:
            logger.error("SerpAPI fetch failed: %s\n%s", str(e), traceback.format_exc())

        # ---------- Smart Question Generator FIRST (category-specific, AI-powered) ----------
        if len(created) < count and SMART_GENERATOR_AVAILABLE:
            try:
                needed = count - len(created)
                logger.info("generate_questions: using smart generator for %s %s questions at %s difficulty", needed, category, difficulty)
                
                smart_questions = await generate_smart_questions(
                    category=category,
                    count=needed,
                    difficulty=difficulty,
                    use_openai=True,
                    company=company if company else None
                )
                
                if smart_questions:
                    created.extend(smart_questions)
                    logger.info("generate_questions: Smart generator produced %s prompts (t=%.2fs)", len(smart_questions), time.time()-t0)
            except Exception as e:
                logger.error("Smart generator failed: %s\n%s", str(e), traceback.format_exc())
        
        # ---------- LLM generation (fallback if smart generator didn't produce enough) ----------
        if len(created) < count:
            needed = count - len(created)
            logger.info("generate_questions: calling LLM to generate %s questions for category=%s", needed, category)
            llm_generated = []

            try:
                # Get category context for better prompts
                category_context = ""
                if SMART_GENERATOR_AVAILABLE:
                    try:
                        from question_generator import get_category_context
                        ctx = get_category_context(category)
                        topics = ", ".join(ctx.get("topics", [])[:8])
                        category_context = f"\nFocus on these topics: {topics}"
                    except:
                        pass
                
                # build a strict user prompt to encourage valid JSON output
                user_prompt = (
                    f"Generate {needed} concise interview questions SPECIFICALLY for the category: '{category}'. "
                    f"{category_context}\n"
                    "IMPORTANT: Questions MUST be relevant to this category ONLY. "
                    "Return ONLY a single valid JSON array of strings and NOTHING else. "
                    "Example: [\"Question 1\",\"Question 2\",...]"
                )
                system_prompt = f"You are an expert {category} interviewer. Generate questions ONLY about {category}. Produce a JSON array of strings."

                # call the LLM. If your call_llm_chat is synchronous, run it in a thread.
                try:
                    # try to await directly (common if wrapper is async)
                    resp = await asyncio.wait_for(call_llm_chat(system_prompt, user_prompt, temperature=0.2), timeout=15)
                except TypeError:
                    # wrapper is synchronous ‚Äî run in thread
                    resp = await asyncio.wait_for(asyncio.to_thread(call_llm_chat, system_prompt, user_prompt, 0.2), timeout=15)
                except asyncio.TimeoutError:
                    logger.error("LLM call timed out after 15s")
                    resp = None

                # Extract text from resp safely
                text = ""
                if resp is None:
                    text = ""
                elif isinstance(resp, dict) and 'choices' in resp:
                    text = resp['choices'][0].get('message', {}).get('content') or resp['choices'][0].get('text', '') or ""
                elif isinstance(resp, str):
                    text = resp
                else:
                    text = getattr(resp, "content", None) or getattr(resp, "text", None) or str(resp)

                text = (text or "").strip()
                logger.info("generate_questions: LLM raw output (first200chars): %s", text[:200].replace("\n", " "))

                # ---------- robust parsing logic ----------
                parsed_list = []

                # 1) If the model returned a fenced code block, extract first fenced block content
                if "```" in text:
                    m = re.search(r"```(?:json)?\s*(.*?)\s*```", text, flags=re.DOTALL | re.IGNORECASE)
                    if m:
                        text_inner = m.group(1).strip()
                    else:
                        text_inner = text.replace("```", "").strip()
                else:
                    text_inner = text

                # 2) Try to pull the first JSON array substring
                json_candidate = None
                if "[" in text_inner and "]" in text_inner:
                    first = text_inner.find("[")
                    last = text_inner.rfind("]")
                    if first != -1 and last != -1 and last > first:
                        json_candidate = text_inner[first:last+1]

                if json_candidate:
                    try:
                        parsed = json.loads(json_candidate)
                        if isinstance(parsed, list):
                            parsed_list = [str(x).strip() for x in parsed if str(x).strip()]
                    except Exception:
                        parsed_list = []

                # 3) If strict JSON failed, extract double-quoted strings
                if not parsed_list:
                    quoted = re.findall(r'"([^"]{5,})"', text_inner)
                    if quoted:
                        parsed_list = [q.strip() for q in quoted]

                # 4) Last fallback: split into sensible lines, strip numbering and punctuation
                if not parsed_list:
                    lines = [ln.strip("-‚Ä¢ \t\n\r ") for ln in text_inner.splitlines() if ln.strip()]
                    candidates = [l for l in lines if len(l) > 10 and not re.fullmatch(r"^[\[\]\{\}`]+$", l)]
                    cleaned = [re.sub(r"^\s*\d{1,2}[\.\)\-]\s*", "", c).strip() for c in candidates]
                    parsed_list = cleaned

                # remove garbage tokens that are just JSON symbols
                parsed_list = [p for p in parsed_list if p and not re.fullmatch(r"^[\[\]\{\}`,\"\s]+$", p)]

                # de-duplicate and trim to needed
                seen = set()
                unique = []
                for q in parsed_list:
                    qn = q.strip()
                    if qn and qn not in seen:
                        seen.add(qn)
                        unique.append(qn)
                llm_generated = unique[:needed]

            except Exception as e:
                logger.error("LLM generation failed: %s\n%s", str(e), traceback.format_exc())
                llm_generated = []

            # append llm results
            if llm_generated:
                start = len(created) + 1
                created.extend([{"id": f"llm-{i+start}", "prompt": q} for i, q in enumerate(llm_generated)])

            logger.info("generate_questions: LLM produced %s prompts (t=%.2fs)", len(llm_generated), time.time()-t0)

        # ---------- Hugging Face fallback (if smart generator and LLM both failed) ----------
        if len(created) < count and HF_AVAILABLE:
            try:
                needed = count - len(created)
                logger.info("generate_questions: trying Hugging Face for %s questions", needed)
                hf_questions = []
                for i in range(needed):
                    try:
                        q = generate_question_hybrid(category, use_openai=False)
                        if q and len(q) > 10:
                            hf_questions.append(q)
                    except Exception as e:
                        logger.error("HF question generation failed: %s", e)
                        continue
                
                if hf_questions:
                    start = len(created) + 1
                    created.extend([{"id": f"hf-{i+start}", "prompt": q} for i, q in enumerate(hf_questions)])
                    logger.info("generate_questions: HF produced %s prompts (t=%.2fs)", len(hf_questions), time.time()-t0)
            except Exception as e:
                logger.error("Hugging Face generation failed: %s\n%s", str(e), traceback.format_exc())

        # ---------- Final fallback: local question bank ----------
        if len(created) < count:
            try:
                logger.info("generate_questions: falling back to LOCAL_QUESTION_BANK")
                local = LOCAL_QUESTION_BANK.get(category) or []
                if not local:
                    all_qs = []
                    for v in LOCAL_QUESTION_BANK.values():
                        all_qs.extend(v)
                    local = all_qs
                for i, q in enumerate(local[:(count - len(created))], start=len(created)+1):
                    created.append({"id": f"local-{i}", "prompt": q})
            except Exception as e:
                logger.error("Fallback local bank failed: %s\n%s", str(e), traceback.format_exc())

        # Ensure we always return a list
        if created is None:
            created = []

        logger.info("generate_questions: returning total_created=%s (total time=%.2fs)", len(created), time.time()-t0)
        return {"created": created}

    except Exception as e:
        tb = traceback.format_exc()
        logger.error("generate_questions error: %s\n%s", str(e), tb)
        raise HTTPException(status_code=500, detail=f"generate_questions failed: {str(e)}")


@app.post("/plagiarism_check")
async def plagiarism_check(payload: dict = None, db=Depends(get_db)):
    """
    Returns:
      { "plagiarism_score": float (0..1), "matches": [ {source, id, sim, excerpt}, ... ] }
    Tries Copyleaks if COPYLEAKS_API_KEY set; else falls back to local similarity.
    """
    data = payload or {}
    text = (data.get("text") or "").strip()
    if not text:
        return JSONResponse({"error": "empty text"}, status_code=400)

    # If Copyleaks credentials provided, submit a quick check (best-effort)
    if COPYLEAKS_API_KEY and COPYLEAKS_EMAIL:
        try:
            # Copyleaks modern API typically wants a file upload and is asynchronous.
            # This small helper uses their "submit /v3/..." flow (you must register).
            # NOTE: For production follow Copyleaks docs & use webhooks for async results.
            headers = {
                "apikey": COPYLEAKS_API_KEY,
                "content-type": "application/json"
            }
          
            import base64
# ...
        # replace payload_to_send creation with:
            b64_text = base64.b64encode(text.encode("utf-8")).decode("utf-8")
            payload_to_send = {
                "base64": b64_text,
                "filename": "submission.txt",
                "properties": {"webhooks": []}
            }


            # THIS REQUEST IS A SCAFFOLD: please adapt to Copyleaks spec per their docs.
            r = requests.post("https://api.copyleaks.com/v3/education/submit/file", headers=headers, json=payload_to_send, timeout=15)
            # If the API accepted, respond with a placeholder and ask user to configure webhooks to retrieve full results
            if r.status_code in (200,201,202):
                return JSONResponse({"plagiarism_score": None, "matches": [], "notice": "Scan submitted to Copyleaks. Configure COPYLEAKS_WEBHOOK_URL to receive results or poll their API."})
        except Exception as e:
            print("Copyleaks request failed:", e)
            # fall through to local check

    # Local fallback (fast): compute similarity to local DB + generated questions
    scored = local_similarity_candidates(text, db=db, top_k=10)
    highest = scored[0]["sim"] if scored else 0.0
    return JSONResponse({"plagiarism_score": round(float(highest), 3), "matches": scored})


@app.post("/evaluate_answer")
async def evaluate_answer(payload: dict = None, db=Depends(get_db)):
    """
    Evaluate an answer using the LLM and run a plagiarism check.
    Request JSON:
      {
        "question_id": "<id returned by /generate_questions (uuid)>",
        "question_text": "<optional direct question string>",
        "answer": "<user answer>",
        "user_id": <optional user id number>
      }
    Response:
      {
        "evaluation": {...},  # LLM JSON or text
        "plagiarism_score": 0.XX,
        "matches": [...]
      }
    """
    data = payload or {}
    answer_text = (data.get("answer") or "").strip()
    if not answer_text:
        return JSONResponse({"error": "empty answer"}, status_code=400)

    # Resolve question text
    question_text = data.get("question_text")
    qid = data.get("question_id")
    if not question_text and qid:
        # try in-memory generated
        meta = app.state.generated_questions.get(qid) if getattr(app.state, "generated_questions", None) else None
        if meta:
            question_text = meta.get("prompt")
        else:
            # try SavedQuestion DB
            try:
                sq = db.query(SavedQuestion).filter_by(id=qid).first()
                if sq:
                    question_text = sq.question
            except Exception:
                question_text = None

    # fallback: if still no question_text, set a generic instruction
    if not question_text:
        question_text = "Unspecified question - please evaluate the answer for correctness, conciseness and clarity."

    # AI Detection Check (runs first, independent of evaluation)
    ai_detection_result = None
    if AI_DETECTION_AVAILABLE:
        try:
            ai_detection_result = detect_ai_generated(answer_text)
            logger.info(f"AI detection: {ai_detection_result['ai_probability']:.2%} probability")
        except Exception as e:
            logger.error(f"AI detection failed: {e}")
    
    # Try Hugging Face hybrid evaluation first (tries OpenAI, falls back to HF)
    evaluation = None
    evaluation_source = "unknown"
    
    if HF_AVAILABLE:
        try:
            # Use hybrid mode: tries OpenAI if available, falls back to Hugging Face
            hf_result = evaluate_answer_hybrid(question_text, answer_text, use_openai=True)
            evaluation = {
                "summary": hf_result.get("feedback", "Answer evaluated"),
                "improvements": [],
                "grammar": "",
                "fillers": "",
                "score": hf_result.get("score", 7.0),
                "sentiment": hf_result.get("sentiment"),
                "relevance": hf_result.get("relevance")
            }
            evaluation_source = hf_result.get("source", "huggingface")
            logger.info(f"Answer evaluated using {evaluation_source}")
        except Exception as e:
            logger.error(f"Hybrid evaluation failed: {e}")
            evaluation = None
    
    # Fallback to direct OpenAI call if HF not available or failed
    if evaluation is None:
        try:
            eval_system = (
                "You are IntervYou: a precise interview answer evaluator. "
                "For the given 'Question' and 'Student answer' produce strict JSON like: "
                '{"summary":"", "improvements":["..."], "grammar":"", "fillers":"", "score": 0.0}. '
                "Keep the response concise and do not output extra commentary."
            )
            user_prompt = f"Question: {question_text}\n\nStudent answer: {answer_text}\n\nReturn JSON as specified."

            llm_resp = await call_llm_chat(eval_system, user_prompt, max_tokens=500)

            # try to parse LLM response as JSON
            try:
                evaluation = json.loads(llm_resp)
                evaluation_source = "openai"
            except Exception:
                # construct a fallback structured evaluation
                evaluation = {"summary": str(llm_resp)[:400], "improvements": [], "grammar": "", "fillers": "", "score": None}
                evaluation_source = "openai_fallback"
        except Exception as e:
            logger.error(f"OpenAI evaluation failed: {e}")
            # Last resort: basic evaluation
            evaluation = {
                "summary": "Unable to evaluate answer. Please try again.",
                "improvements": ["Ensure your answer is clear and addresses the question"],
                "grammar": "",
                "fillers": "",
                "score": 5.0
            }
            evaluation_source = "fallback"
    
    # Add source to evaluation
    evaluation["evaluation_source"] = evaluation_source
    
    # Add AI detection results to evaluation
    if ai_detection_result:
        evaluation["ai_detection"] = {
            "ai_probability": ai_detection_result["ai_probability"],
            "confidence": ai_detection_result["confidence"],
            "warning": ai_detection_result["warning"],
            "verdict": ai_detection_result["verdict"],
            "indicators": ai_detection_result["indicators"][:3]  # Top 3 indicators
        }
        
        # Apply score penalty for high AI probability
        if ai_detection_result["ai_probability"] >= 0.7:
            # Severe penalty for likely AI-generated content
            original_score = evaluation.get("score", 0)
            evaluation["score"] = min(original_score * 0.3, 3.0)  # Max 3/10 for AI content
            evaluation["ai_penalty_applied"] = True
            evaluation["original_score"] = original_score
        elif ai_detection_result["ai_probability"] >= 0.5:
            # Moderate penalty for possibly AI-generated
            original_score = evaluation.get("score", 0)
            evaluation["score"] = original_score * 0.6  # 40% penalty
            evaluation["ai_penalty_applied"] = True
            evaluation["original_score"] = original_score

    # run local plagiarism check
    plag_payload = {"text": answer_text}
    plag_result = await plagiarism_check(plag_payload, db=db)
    try:
        plag_json = json.loads(plag_result.body.decode()) if hasattr(plag_result, "body") else plag_result
    except Exception:
        # if plagiarism_check already returned a JSONResponse
        try:
            plag_json = plag_result
        except Exception:
            plag_json = {"plagiarism_score": 0.0, "matches": []}

    # Save attempt (best-effort)
    try:
        current_user = None
        # if payload provided a user_id, attempt to use it; else ignore
        user_id = data.get("user_id")
        if user_id:
            current_user = db.query(User).filter_by(id=user_id).first()
        # use Attempt model to record the attempt if it exists
        at = Attempt(user_id=(current_user.id if current_user else (user_id or 0)),
                     question=question_text,
                     score=(evaluation.get("score") if isinstance(evaluation, dict) else None),
                     feedback=json.dumps(evaluation),
                     timestamp=datetime.utcnow())
        db.add(at)
        db.commit()
    except Exception:
        # swallow DB errors (do not break evaluation)
        try:
            db.rollback()
        except Exception:
            pass

    return JSONResponse({"evaluation": evaluation, "plagiarism_score": plag_json.get("plagiarism_score", 0.0), "matches": plag_json.get("matches", [])})


# ---------------- CLEAR QUESTION CACHE ----------------
@app.post("/clear_question_cache")
async def clear_question_cache(request: Request):
    """Clear all cached questions from session"""
    try:
        # Clear all question-related session data
        keys_to_clear = [
            "category_questions",
            "mock_questions",
            "question_index",
            "mock_index",
            "last_category"
        ]
        
        # Clear category-specific caches
        for key in list(request.session.keys()):
            if key.startswith("questions_"):
                keys_to_clear.append(key)
        
        for key in keys_to_clear:
            if key in request.session:
                del request.session[key]
        
        print(f"üóëÔ∏è  Cleared {len(keys_to_clear)} question cache keys")
        return JSONResponse({"success": True, "message": "Question cache cleared"})
    except Exception as e:
        return JSONResponse({"success": False, "error": str(e)}, status_code=500)


# ---------------- SET CATEGORY ----------------
@app.post("/set_category")
async def set_category(request: Request, data: dict = None):
    """
    Enhanced category selection with automatic AI question generation.
    Generates 10 questions per category and caches them for the session.
    Supports company-specific filtering.
    """
    global current_category, current_question
    payload = data or await request.json()
    category = payload.get("category", "General")
    difficulty = payload.get("difficulty", "medium")  # beginner, intermediate, advanced
    company = payload.get("company", "")  # Company filter (optional)
    
    # Map frontend difficulty names to generator names
    difficulty_map = {
        "beginner": "easy",
        "intermediate": "medium",
        "advanced": "hard"
    }
    generator_difficulty = difficulty_map.get(difficulty, "medium")
    
    # Store category, difficulty, and company in session
    request.session["current_category"] = category
    request.session["current_difficulty"] = difficulty
    request.session["current_company"] = company
    current_category = category
    
    # IMPORTANT: Clear old category/company questions to prevent cross-contamination
    old_category = request.session.get("last_category")
    old_company = request.session.get("last_company", "")
    
    # Clear cache if category OR company changed
    if (old_category and old_category != category) or (old_company != company):
        # Clear old category+company cache
        old_company_suffix = f"_{old_company}" if old_company else ""
        old_key = f"questions_{old_category}{old_company_suffix}"
        if old_key in request.session:
            del request.session[old_key]
        # Clear general category questions
        if "category_questions" in request.session:
            del request.session["category_questions"]
        print(f"üóëÔ∏è  Cleared old questions for category: {old_category}, company: {old_company or 'None'}")
    
    request.session["last_category"] = category
    request.session["last_company"] = company
    
    # Check if we should force refresh (bypass cache)
    force_refresh = payload.get("force_refresh", False)
    
    # Check if we already have cached questions for this category+company combination
    # Include company in cache key to avoid mixing generic and company-specific questions
    company_suffix = f"_{company}" if company else ""
    session_key = f"questions_{category}{company_suffix}"
    cached_questions = request.session.get(session_key, [])
    
    if cached_questions and len(cached_questions) >= 5 and not force_refresh:
        # Use cached questions
        request.session["category_questions"] = cached_questions
        request.session["question_index"] = 0
        print(f"‚úÖ Using {len(cached_questions)} cached questions for category: {category}")
        print(f"üìù First cached question: {cached_questions[0][:80]}...")
        return JSONResponse({
            "next_question": cached_questions[0],
            "ai_generated": True,
            "total_questions": len(cached_questions),
            "category": category
        })
    
    # If force_refresh or no cache, clear old cache
    if force_refresh and session_key in request.session:
        del request.session[session_key]
        print(f"üîÑ Force refresh: cleared cache for {category}")
    
    # Generate fresh AI questions for this category
    print(f"üîÑ Generating new questions for category: {category}" + (f" (Company: {company})" if company else ""))
    try:
        # Use the robust generate_questions endpoint with company context
        gen_payload = {"category": category, "count": 10}
        if company:
            gen_payload["company"] = company
        gen_result = await generate_questions(gen_payload)
        
        if gen_result and gen_result.get("created"):
            questions = [item["prompt"] for item in gen_result["created"]]
            
            if questions:
                # Debug: Log first question to verify category match
                print(f"üìù First question for {category}: {questions[0][:80]}...")
                
                # Cache in session for this category
                request.session[session_key] = questions
                request.session["category_questions"] = questions
                request.session["question_index"] = 0
                
                # Update global state
                refresh_current_question(category)
                
                print(f"‚úÖ Generated {len(questions)} AI questions for category: {category}")
                return JSONResponse({
                    "next_question": questions[0],
                    "ai_generated": True,
                    "total_questions": len(questions),
                    "category": category,
                    "message": f"Generated {len(questions)} fresh questions for {category}"
                })
    except Exception as e:
        print(f"‚ö†Ô∏è AI question generation failed: {e}")
        import traceback
        traceback.print_exc()
    
    # Fallback to local question bank
    if category in LOCAL_QUESTION_BANK:
        local_questions = LOCAL_QUESTION_BANK[category]
        request.session["category_questions"] = local_questions
        request.session["question_index"] = 0
        refresh_current_question(category)
        print(f"‚úÖ Using {len(local_questions)} local questions for category: {category}")
        return JSONResponse({
            "next_question": local_questions[0],
            "ai_generated": False,
            "total_questions": len(local_questions),
            "category": category
        })
    
    # Last resort fallback
    fallback_question = f"Tell me about your experience with {category}."
    request.session["category_questions"] = [fallback_question]
    request.session["question_index"] = 0
    return JSONResponse({
        "next_question": fallback_question,
        "ai_generated": False,
        "category": category
    })

# ---------------- SAVE / SAVED / DELETE ----------------
@app.post("/save_question")
def save_question(request: Request, payload: dict = None, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"error": "Not authenticated"}, status_code=401)
    data = payload or {}
    question_text = data.get("question")
    if not question_text:
        return JSONResponse({"error": "Missing question text"}, status_code=400)
    existing = db.query(SavedQuestion).filter_by(user_id=user.id, question=question_text).first()
    if existing:
        return JSONResponse({"message": "‚úÖ Already saved."})
    new_saved = SavedQuestion(user_id=user.id, question=question_text)
    db.add(new_saved)
    db.commit()
    return JSONResponse({"message": "‚≠ê Question saved successfully!"})


@app.get("/saved", response_class=HTMLResponse)
def saved_questions(request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")
    saved = db.query(SavedQuestion).filter_by(user_id=user.id).order_by(SavedQuestion.timestamp.desc()).all()
    return templates.TemplateResponse("saved.html", {"request": request, "saved": saved})


@app.delete("/delete_saved/{sid}")
def delete_saved(sid: int, request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"error": "Not authenticated"}, status_code=401)
    saved = db.query(SavedQuestion).filter_by(id=sid, user_id=user.id).first()
    if not saved:
        return JSONResponse({"error": "Saved question not found."}, status_code=404)
    db.delete(saved)
    db.commit()
    return JSONResponse({"message": "üóë Deleted successfully!"})

# fastapi_app.py -- add this near your saved/delete endpoints

@app.post("/saved/delete/{sid}")
def saved_delete_post(sid: int, request: Request, db=Depends(get_db)):
    """
    Template uses fetch('/saved/delete/'+id, { method:'POST' }) so support that.
    This will reuse delete logic from delete_saved but fit the template's call.
    """
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"error": "Not authenticated"}, status_code=401)
    saved = db.query(SavedQuestion).filter_by(id=sid, user_id=user.id).first()
    if not saved:
        return JSONResponse({"error": "Saved question not found."}, status_code=404)
    db.delete(saved)
    db.commit()
    return JSONResponse({"message": "üóë Deleted successfully!"})



# ---------------- EXPORT PDF ----------------
@app.get("/export_pdf")
def export_pdf(request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")
    saved_questions = db.query(SavedQuestion).filter_by(user_id=user.id).order_by(SavedQuestion.timestamp.desc()).all()
    if not saved_questions:
        add_flash(request, "No saved questions to export!", "warning")
        return RedirectResponse("/saved", status_code=303)

    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter,
                            leftMargin=72, rightMargin=72, topMargin=72, bottomMargin=72)
    styles = getSampleStyleSheet()
    story = []
    title = Paragraph(f"<b>‚≠ê Saved Questions ‚Äî {user.name}</b>", styles['Title'])
    story.append(title)
    story.append(Spacer(1, 0.25 * inch))
    for i, q in enumerate(saved_questions, start=1):
        text = f"<b>{i}. {q.question}</b><br/><font size=9 color=gray>Saved on {q.timestamp.strftime('%b %d, %Y ‚Äî %I:%M %p')}</font>"
        story.append(Paragraph(text, styles['BodyText']))
        story.append(Spacer(1, 0.2 * inch))
    doc.build(story)
    buffer.seek(0)
    headers = {"Content-Disposition": "attachment; filename=saved_questions.pdf"}
    return StreamingResponse(buffer, media_type="application/pdf", headers=headers)


# ---------------- VOICE ANALYSIS ----------------
@app.post("/transcribe")
def transcribe_audio_endpoint(file: UploadFile = File(...), db=Depends(get_db), request: Request = None):
    """
    Transcribe audio to text using Whisper AI
    Returns: {"transcription": "text", "duration": seconds}
    """
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"error": "Not authenticated"}, status_code=401)
    
    try:
        saved_path = save_upload_sync(file, UPLOAD_FOLDER)
    except Exception as e:
        print("Save audio failed:", e)
        return JSONResponse({"error": "Could not save uploaded file"}, status_code=500)
    
    try:
        # Get audio duration
        import librosa
        y, sr = librosa.load(saved_path, sr=None)
        duration = float(len(y) / sr)
        
        # Transcribe using Whisper
        transcription = hf_transcribe_audio(saved_path)
        
        if not transcription:
            return JSONResponse({"error": "Transcription failed - no speech detected"}, status_code=400)
        
        return JSONResponse({
            "transcription": transcription,
            "duration": round(duration, 2),
            "word_count": len(transcription.split()),
            "status": "success"
        })
    except Exception as e:
        print("Transcription error:", e)
        return JSONResponse({"error": f"Transcription failed: {str(e)}"}, status_code=500)


@app.post("/voice")
def analyze_voice(file: UploadFile = File(...), db=Depends(get_db), request: Request = None):
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"error": "Not authenticated"}, status_code=401)
    
    # Save uploaded voice file safely
    try:
        saved_path = save_upload_sync(file, UPLOAD_FOLDER)
    except Exception as e:
        print("Save voice failed:", e)
        return JSONResponse({"error": "Could not save uploaded file"}, status_code=500)

    try:
        # Transcribe audio using Whisper
        transcription = ""
        try:
            transcription = hf_transcribe_audio(saved_path)
            print(f"Whisper transcription: {transcription}")
        except Exception as e:
            print(f"Whisper transcription failed: {e}")
            transcription = "[Transcription unavailable]"
        
        # Audio analysis (energy/pitch)
        y, sr = librosa.load(saved_path, sr=None)
        rms = librosa.feature.rms(y=y)
        energy = float(np.mean(rms)) if rms.size else 0.0
        
        try:
            pitch = float(np.mean(librosa.yin(y, fmin=80, fmax=400)))
        except Exception:
            pitch = 0.0
        
        # Tone classification
        if energy > 0.05 and pitch > 150:
            tone = "Energetic / Confident"
        elif energy < 0.02:
            tone = "Uncertain / Low Energy"
        else:
            tone = "Calm / Neutral Tone"
        
        return JSONResponse({
            "result": tone,
            "transcription": transcription,
            "energy": round(energy, 3),
            "pitch": round(pitch, 1)
        })
    except Exception as e:
        print("Audio analysis error:", e)
        return JSONResponse({"error": "Could not process audio file"}, status_code=500)


# ---------------- REPORT (robust version) ----------------
@app.get("/report", response_class=HTMLResponse)
def report(request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")

    attempts = db.query(Attempt).filter_by(user_id=user.id).order_by(Attempt.timestamp.desc()).limit(10).all()

    # safe defaults if no attempts
    if not attempts:
        average = 0
        remark = "No data yet."
        chart_labels = []
        chart_scores = []
    else:
        scores = [a.score for a in attempts if a.score is not None]
        average = round(sum(scores) / len(scores), 1) if scores else 0
        remark = "Excellent performance!" if average >= 8 else "Good ‚Äî keep practicing." if average >= 5 else "Needs improvement."
        # keep label lengths sane for chart
        chart_labels = [(a.question[:20] + "...") if len(a.question or "") > 20 else (a.question or "") for a in attempts][::-1]
        chart_scores = [a.score or 0 for a in attempts][::-1]

    # Get top learners from database
    top_learners = []
    try:
        all_users = db.query(User).all()
        for u in all_users:
            if u.attempts > 0:
                avg = round(u.total_score / u.attempts, 1)
                top_learners.append({"name": u.name, "avg": avg})
        top_learners = sorted(top_learners, key=lambda x: x["avg"], reverse=True)[:3]
    except Exception:
        top_learners = []

    return templates.TemplateResponse(
        "report.html",
        {
            "request": request,
            "attempts": attempts,
            "average": average,
            "remark": remark,
            "chart_labels": chart_labels,
            "chart_scores": chart_scores,
            "user": user,
            "top_learners": top_learners,
        },
    )
# ---------------- REPORT END ----------------

# ---------------- PROFILE (accurate chart ‚Äî no fake scores) ----------------
@app.get("/profile", response_class=HTMLResponse)
def profile(request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")

    # Get user attempts
    attempts = db.query(Attempt).filter_by(user_id=user.id).order_by(Attempt.timestamp.desc()).all()

    total_attempts = len(attempts)
    if total_attempts == 0:
        avg_score = 0.0
        best_score = 0.0
        categories = list(app.state.question_bank.keys()) if hasattr(app.state, "question_bank") else []
        category_labels = categories
        category_scores = []  # empty so chart shows no bars
        ai_summary = "üöÄ No data yet ‚Äî start your first mock interview or practice session!"
    else:
        # collect numeric scores safely (ignore None)
        scores = [float(a.score) for a in attempts if a.score is not None]
        avg_score = round(sum(scores) / len(scores), 1) if scores else 0.0
        best_score = max(scores) if scores else 0.0

        # Compute category-wise averages robustly.
        # question_bank may contain lists of either strings or dicts like {"q": "..."}.
        question_bank = getattr(app.state, "question_bank", {}) or {}
        category_scores_map = {cat: [] for cat in question_bank.keys()}

        def question_text_from_item(item):
            """
            Normalize a question item from question_bank into plain string text.
            Accepts:
              - string "Explain..."
              - dict {"q": "..."} or {"prompt": "..."}
              - object with str() fallback
            """
            try:
                if isinstance(item, dict):
                    return item.get("q") or item.get("prompt") or str(item)
                elif isinstance(item, str):
                    return item
                else:
                    return str(item)
            except Exception:
                return str(item)

        # For each attempt, try to attribute it to a category by matching text
        for attempt in attempts:
            att_q = (attempt.question or "").strip()
            if not att_q:
                continue
            matched = False
            for cat, qlist in question_bank.items():
                # qlist might be list[str] or list[dict]
                for qitem in (qlist or []):
                    qtext = question_text_from_item(qitem)
                    if not qtext:
                        continue
                    # use a simple similarity check: exact match or substring or difflib ratio > 0.75
                    try:
                        if qtext.strip() == att_q:
                            category_scores_map.setdefault(cat, []).append(attempt.score or 0)
                            matched = True
                            break
                        if att_q in qtext or qtext in att_q:
                            category_scores_map.setdefault(cat, []).append(attempt.score or 0)
                            matched = True
                            break
                        # difflib fallback
                        if difflib.SequenceMatcher(None, qtext, att_q).ratio() > 0.75:
                            category_scores_map.setdefault(cat, []).append(attempt.score or 0)
                            matched = True
                            break
                    except Exception:
                        continue
                if matched:
                    break
            # if not matched keep it unclassified (we ignore for category averages)

        category_labels = list(category_scores_map.keys())
        category_scores = [
            round(sum(vals) / len(vals), 1) if vals else 0
            for vals in category_scores_map.values()
        ]

        ai_summary = (
            "üåü Excellent consistency! You‚Äôre interview-ready." if avg_score >= 8 else
            "üí™ You‚Äôre improving! Keep refining your answers." if avg_score >= 5 else
            "üöÄ Keep practicing ‚Äî your progress will show soon!"
        )

    badge = user.badge or "üéØ Rising Learner"

    return templates.TemplateResponse(
        "profile.html",
        {
            "request": request,
            "user": user,
            "attempts": attempts,
            "total_attempts": total_attempts,
            "average_score": avg_score,
            "best_score": best_score,
            "ai_summary": ai_summary,
            "badge": badge,
            "category_labels": category_labels,
            "category_scores": category_scores,
        },
    )
# ---------------- PROFILE END ----------------


# ---------------- ADVISOR ----------------
@app.get("/advisor", response_class=HTMLResponse)
def advisor(request: Request, db=Depends(get_db)):
    """
    AI-powered advisor that analyzes user's performance and provides personalized learning plans.
    """
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")

    # fetch recent attempts (most recent first)
    attempts = db.query(Attempt).filter_by(user_id=user.id).order_by(Attempt.timestamp.desc()).limit(20).all()

    # Compute simple metrics
    if not attempts:
        avg_score = 0
        recent_weaknesses = ["No data yet ‚Äî complete some practice sessions to get personalized advice."]
        recent_strengths = ["Ready to start your journey!"]
        recommendation = "Start with a mock interview to generate personalized advice."
        plans = []
    else:
        scores = [a.score or 0 for a in attempts]
        avg_score = round(sum(scores) / len(scores), 1) if scores else 0

        # Analyze feedback for patterns
        combined_feedback = " ".join((a.feedback or "").lower() for a in attempts)
        weaknesses = []
        if ("too short" in combined_feedback) or ("short" in combined_feedback):
            weaknesses.append("Length ‚Äî answers are short; add examples & structure.")
        if ("fillers" in combined_feedback) or ("try to avoid fillers" in combined_feedback):
            weaknesses.append("Fillers ‚Äî reduce 'um/uh/like' for clarity.")
        if ("grammar" in combined_feedback) or ("grammar issue" in combined_feedback):
            weaknesses.append("Grammar/phrasing ‚Äî practice clear sentence structure.")
        if ("consider including" in combined_feedback) or ("missing" in combined_feedback):
            weaknesses.append("Missing key points ‚Äî practice mentioning required keywords.")

        if not weaknesses:
            weaknesses = ["No consistent weak pattern detected; keep practicing for refinement."]

        # Identify strengths
        strengths = []
        if "positive and confident" in combined_feedback or "tone: positive" in combined_feedback:
            strengths.append("Confident tone")
        if "good length" in combined_feedback or "good ‚Äî no filler" in combined_feedback:
            strengths.append("Good answer length / clarity")
        if avg_score >= 7:
            strengths.append("Strong overall performance")

        if not strengths:
            strengths = ["Consistent attempts ‚Äî keep building fluency."]

        recent_weaknesses = weaknesses
        recent_strengths = strengths

        # Generate recommendation based on avg_score
        if avg_score >= 8:
            recommendation = "Great work! Focus on polishing delivery and advanced examples."
        elif avg_score >= 5:
            recommendation = "Solid progress. Practice structured answers (STAR) and reduce filler words."
        else:
            recommendation = "Start with short, focused practice: 5‚Äì10 minute daily mock interviews focusing on one topic."

        # Create personalized learning plans
        plans = []
        
        # Plan 1: Daily Practice Routine
        plans.append({
            "id": "daily-practice",
            "title": "üìÖ Daily Practice Routine",
            "summary": "Build consistency with focused daily practice sessions",
            "estimated_time": "15 min/day",
            "steps": [
                "Practice 5 mock questions daily (60s each)",
                "Record 2 answers and review for fillers/energy",
                "Save commonly asked questions for review"
            ],
            "resources": ["/practice", "/mock_interview"]
        })
        
        # Plan 2: Weakness-focused training
        if avg_score < 7:
            plans.append({
                "id": "improve-weak-areas",
                "title": "üéØ Improve Weak Areas",
                "summary": f"Focus on: {', '.join(weaknesses[:2])}",
                "estimated_time": "20 min/day",
                "steps": [
                    "Identify your top 3 weak categories",
                    "Practice 10 questions in each weak category",
                    "Review AI feedback and adjust approach",
                    "Re-test after 1 week to measure improvement"
                ],
                "resources": ["/practice", "/report"]
            })
        
        # Plan 3: Advanced preparation
        if avg_score >= 7:
            plans.append({
                "id": "advanced-prep",
                "title": "üöÄ Advanced Interview Prep",
                "summary": "Master complex scenarios and behavioral questions",
                "estimated_time": "30 min/day",
                "steps": [
                    "Practice system design questions",
                    "Master STAR method for behavioral questions",
                    "Record and analyze your body language",
                    "Practice with time constraints"
                ],
                "resources": ["/video_interview", "/mock_interview"]
            })
        
        # Plan 4: Category mastery
        plans.append({
            "id": "category-mastery",
            "title": "üìö Category Mastery",
            "summary": "Become an expert in specific interview categories",
            "estimated_time": "25 min/day",
            "steps": [
                "Choose 2-3 categories to master",
                "Complete 20 questions per category",
                "Study common patterns and best answers",
                "Achieve 8+ average score in each category"
            ],
            "resources": ["/practice", "/profile"]
        })

    return templates.TemplateResponse(
        "advisor.html",
        {
            "request": request,
            "user": user,
            "attempts": attempts,
            "avg_score": avg_score,
            "weaknesses": recent_weaknesses,
            "strengths": recent_strengths,
            "recommendation": recommendation,
            "plans": plans,
        },
    )

@app.get("/advisor/details/{plan_id}", response_class=HTMLResponse)
def advisor_details(plan_id: str, request: Request, db=Depends(get_db)):
    """Show detailed information about a specific learning plan"""
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")
    
    # Define all available plans
    all_plans = {
        "daily-practice": {
            "title": "üìÖ Daily Practice Routine",
            "summary": "Build consistency with focused daily practice sessions",
            "steps": [
                "Practice 5 mock questions daily (60 seconds each)",
                "Record 2 answers per day and review the audio for fillers/energy",
                "Save 10 commonly asked questions and draft bullet-point answers",
                "Track your progress in the report section",
                "Aim for consistency over perfection"
            ],
            "resources": [
                "/practice - Start practicing",
                "/mock_interview - Full mock interview",
                "/report - Track your progress"
            ]
        },
        "improve-weak-areas": {
            "title": "üéØ Improve Weak Areas",
            "summary": "Targeted practice to strengthen your weaknesses",
            "steps": [
                "Review your report to identify weak categories",
                "Focus on your bottom 3 categories",
                "Practice 10 questions in each weak category",
                "Review AI feedback carefully and adjust your approach",
                "Re-test after 1 week to measure improvement"
            ],
            "resources": [
                "/report - View your weak areas",
                "/practice - Practice by category",
                "/profile - Track category scores"
            ]
        },
        "advanced-prep": {
            "title": "üöÄ Advanced Interview Prep",
            "summary": "Master complex scenarios and behavioral questions",
            "steps": [
                "Practice system design and architecture questions",
                "Master the STAR method (Situation, Task, Action, Result)",
                "Record video interviews and analyze body language",
                "Practice with strict time constraints",
                "Prepare for follow-up questions"
            ],
            "resources": [
                "/video_interview - Practice with video",
                "/mock_interview - Timed practice",
                "/saved - Review saved questions"
            ]
        },
        "category-mastery": {
            "title": "üìö Category Mastery",
            "summary": "Become an expert in specific interview categories",
            "steps": [
                "Choose 2-3 categories you want to master",
                "Complete at least 20 questions per category",
                "Study common patterns and best practice answers",
                "Achieve 8+ average score in each category",
                "Help others by sharing your knowledge"
            ],
            "resources": [
                "/practice - Practice by category",
                "/profile - View category breakdown",
                "/leaderboard - Compare with others"
            ]
        }
    }
    
    plan = all_plans.get(plan_id)
    if not plan:
        return RedirectResponse("/advisor")
    
    return templates.TemplateResponse(
        "advisor_details.html",
        {
            "request": request,
            "user": user,
            "plan": plan
        }
    )

@app.get("/advisor/start/{plan_id}", response_class=HTMLResponse)
def advisor_start(plan_id: str, request: Request, db=Depends(get_db)):
    """Start a learning plan"""
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")
    
    plan_titles = {
        "daily-practice": "Daily Practice Routine",
        "improve-weak-areas": "Improve Weak Areas",
        "advanced-prep": "Advanced Interview Prep",
        "category-mastery": "Category Mastery"
    }
    
    plan_title = plan_titles.get(plan_id, "Learning Plan")
    
    return templates.TemplateResponse(
        "advisor_start.html",
        {
            "request": request,
            "user": user,
            "plan_title": plan_title,
            "plan_id": plan_id
        }
    )
# ---------------- ADVISOR END ----------------

# ---------------- LEADERBOARD ----------------
@app.get("/leaderboard", response_class=HTMLResponse)
def leaderboard(request: Request, db=Depends(get_db)):
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")
    users = db.query(User).all()
    leaderboard_data = []
    for u in users:
        avg = (u.total_score / u.attempts) if u.attempts else 0
        leaderboard_data.append({"name": u.name, "badge": u.badge, "avg": round(avg, 1)})
    leaderboard_data = sorted(leaderboard_data, key=lambda x: x["avg"], reverse=True)
    for i, row in enumerate(leaderboard_data):
        row["rank"] = i + 1
    return templates.TemplateResponse("leaderboard.html", {"request": request, "leaderboard": leaderboard_data, "user": user})


# --- VIDEO INTERVIEW: add below other routes in fastapi_app.py ---
from fastapi import UploadFile, File, BackgroundTasks
from moviepy.video.io.VideoFileClip import VideoFileClip
from moviepy.audio.io.AudioFileClip import AudioFileClip
import uuid
import shutil

VIDEO_UPLOAD_DIR = os.path.join(STATIC_DIR, "uploads")
os.makedirs(VIDEO_UPLOAD_DIR, exist_ok=True)

def extract_audio_from_video(video_path: str, out_audio_path: str):
    """
    Synchronous helper to extract audio using moviepy.
    Requires ffmpeg installed on server.
    """
    try:
        clip = VideoFileClip(video_path)
        # write_audiofile will create a .wav or .mp3 depending on extension
        if clip.audio is None:
            print("Warning: Video has no audio track")
            # Create a silent audio file as placeholder
            import numpy as np
            import soundfile as sf
            silent_audio = np.zeros((44100, 2))  # 1 second of silence
            sf.write(out_audio_path, silent_audio, 44100)
        else:
            clip.audio.write_audiofile(out_audio_path, logger=None)
            clip.reader.close()
            clip.audio.reader.close_proc()
    except Exception as e:
        print(f"Audio extraction failed: {e}")
        # Create a placeholder silent audio file
        try:
            import numpy as np
            import soundfile as sf
            silent_audio = np.zeros((44100, 2))
            sf.write(out_audio_path, silent_audio, 44100)
            print("Created placeholder audio file")
        except:
            raise e

def analyze_audio_file(path: str):
    """
    Runs the same logic as your /voice endpoint to return a tone classification.
    Keep this consistent with your existing voice analysis code.
    """
    try:
        y, sr = librosa.load(path, sr=None)
        rms = librosa.feature.rms(y=y)
        energy = float(np.mean(rms)) if rms.size else 0.0
        try:
            pitch = float(np.mean(librosa.yin(y, fmin=80, fmax=400)))
        except Exception:
            pitch = 0.0
        if energy > 0.05 and pitch > 150:
            result = "Energetic / Confident"
        elif energy < 0.02:
            result = "Uncertain / Low Energy"
        else:
            result = "Calm / Neutral Tone"
        return {"result": result, "energy": energy, "pitch": pitch}
    except Exception as e:
        print("Audio analysis error:", e)
        return {"error": "Could not process audio file"}

@app.get("/video_interview", response_class=HTMLResponse)
def video_interview_page(request: Request, db=Depends(get_db)):
    """Video interview practice page with AI-powered analysis"""
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login")
    
    # Get a random interview question
    question = get_current_question_obj().get("q", "Tell me about a challenging project you worked on.")
    
    # List previous uploads (optional)
    files = []
    try:
        for fname in os.listdir(VIDEO_UPLOAD_DIR):
            if fname.lower().endswith((".webm", ".mp4", ".ogg", ".mov")):
                files.append(fname)
    except Exception:
        pass
    
    return templates.TemplateResponse("video_interview.html", {
        "request": request, 
        "user": user, 
        "files": files,
        "question": question
    })


@app.get("/api/video_analysis/status")
def video_analysis_status():
    """Check which video analysis features are available"""
    try:
        from video_analysis import FER_AVAILABLE, DEEPFACE_AVAILABLE, MEDIAPIPE_AVAILABLE
        import cv2
        import librosa
        from textblob import TextBlob
        
        return JSONResponse({
            "status": "operational",
            "features": {
                "core": {
                    "opencv": True,
                    "librosa": True,
                    "textblob": True,
                    "basic_analysis": True
                },
                "advanced": {
                    "fer_emotion_detection": FER_AVAILABLE,
                    "deepface_analysis": DEEPFACE_AVAILABLE,
                    "mediapipe_pose": MEDIAPIPE_AVAILABLE
                }
            },
            "recommendations": {
                "fer": "pip install fer" if not FER_AVAILABLE else "‚úÖ Installed",
                "deepface": "pip install deepface" if not DEEPFACE_AVAILABLE else "‚úÖ Installed",
                "mediapipe": "pip install mediapipe" if not MEDIAPIPE_AVAILABLE else "‚úÖ Installed"
            }
        })
    except Exception as e:
        return JSONResponse({
            "status": "error",
            "error": str(e),
            "message": "Video analysis module not properly configured"
        }, status_code=500)

@app.post("/upload_video")
async def upload_video(request: Request,
                       video: UploadFile = File(...),
                       question: str = Form(default=""),
                       background: BackgroundTasks = None,
                       db=Depends(get_db)):
    """
    Accepts a recorded video from the browser, performs comprehensive AI analysis including:
    - Emotion detection
    - Facial expression analysis
    - Body language assessment
    - Sentiment analysis
    - Audio/speech analysis
    Returns detailed feedback and scores.
    """
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"error": "Not authenticated"}, status_code=401)

    # Create unique filenames
    ext = os.path.splitext(video.filename)[1] or ".webm"
    uid = uuid.uuid4().hex[:12]
    safe_video_name = f"video_{user.id}_{uid}{ext}"
    video_path = os.path.join(VIDEO_UPLOAD_DIR, safe_video_name)

    # Save uploaded file
    try:
        with open(video_path, "wb") as f:
            shutil.copyfileobj(video.file, f)
    except Exception as e:
        print("Save video failed:", e)
        return JSONResponse({"error": "Could not save uploaded file"}, status_code=500)

    # Prepare paths for extracted audio
    audio_filename = f"audio_from_{uid}.wav"
    audio_path = os.path.join(UPLOAD_FOLDER, audio_filename)

    try:
        # Import video analysis module
        from video_analysis import analyze_video_comprehensive, get_quick_feedback
        
        # Extract audio for speech analysis
        try:
            extract_audio_from_video(video_path, audio_path)
            audio_analysis = analyze_audio_file(audio_path)
        except Exception as audio_error:
            print(f"Audio extraction error: {audio_error}")
            audio_analysis = {"result": "Unable to analyze audio", "error": str(audio_error)}
        
        # Perform comprehensive video analysis
        try:
            video_analysis = analyze_video_comprehensive(video_path)
            
            # Check validation results
            validation = video_analysis.get("validation", {})
            if not validation.get("is_valid", True):
                # Video failed validation - return early with low scores and helpful feedback
                return JSONResponse({
                    "success": False,
                    "message": "Video quality insufficient for analysis",
                    "score": validation.get("suggested_score", 0.0),
                    "feedback": "\n".join([
                        f"‚ö†Ô∏è Video Analysis Issues Detected:",
                        "",
                        *[f"‚ùå {issue}" for issue in validation.get("issues", [])],
                        "",
                        "üìã Recommendations:",
                        *validation.get("recommendations", []),
                        "",
                        f"‚≠ê Current Score: {validation.get('suggested_score', 0.0)}/10",
                        "",
                        "üí° Tips for better results:",
                        "  ‚Ä¢ Record for at least 30-60 seconds",
                        "  ‚Ä¢ Speak clearly and answer the question thoroughly",
                        "  ‚Ä¢ Ensure good lighting and camera positioning",
                        "  ‚Ä¢ Check that your microphone is working"
                    ]),
                    "validation": validation,
                    "detailed_analysis": {
                        "confidence_score": validation.get("suggested_score", 0.0),
                        "professionalism_score": validation.get("suggested_score", 0.0),
                        "engagement_score": validation.get("suggested_score", 0.0),
                        "validation_failed": True
                    }
                }, status_code=400)
                
        except Exception as video_error:
            print(f"Video analysis error: {video_error}")
            # Fallback to basic scores only if there's a system error
            video_analysis = {
                "confidence_score": 0.0,
                "professionalism_score": 0.0,
                "engagement_score": 0.0,
                "emotions": {"dominant_emotion": "neutral"},
                "facial_analysis": {},
                "body_language": {},
                "recommendations": ["Unable to analyze video. Please try again with a clear recording."]
            }
        
        # Transcribe audio if available (using existing HF utilities)
        transcription = ""
        ai_text_analysis = {}
        
        if HF_AVAILABLE and os.path.exists(audio_path):
            try:
                transcription = hf_transcribe_audio(audio_path)
                
                # Enhanced AI analysis using free models
                if transcription and len(transcription.strip()) > 10:
                    try:
                        from free_ai_models import get_free_ai_analyzer
                        ai_analyzer = get_free_ai_analyzer()
                        
                        # Comprehensive text analysis
                        ai_text_analysis = ai_analyzer.analyze_interview_response(transcription)
                        
                        # Use AI sentiment if available, otherwise fallback to TextBlob
                        if ai_text_analysis.get("sentiment"):
                            video_analysis["sentiment"] = ai_text_analysis["sentiment"]
                            video_analysis["ai_emotion"] = ai_text_analysis.get("emotion", {})
                            video_analysis["text_quality"] = ai_text_analysis.get("quality", {})
                        else:
                            # Fallback to TextBlob
                            from textblob import TextBlob
                            blob = TextBlob(transcription)
                            video_analysis["sentiment"] = {
                                "label": "POSITIVE" if blob.sentiment.polarity > 0.1 else "NEGATIVE" if blob.sentiment.polarity < -0.1 else "NEUTRAL",
                                "score": round(abs(blob.sentiment.polarity), 3)
                            }
                    except Exception as ai_error:
                        print(f"AI text analysis error: {ai_error}")
                        # Fallback to TextBlob
                        from textblob import TextBlob
                        blob = TextBlob(transcription)
                        video_analysis["sentiment"] = {
                            "label": "POSITIVE" if blob.sentiment.polarity > 0.1 else "NEGATIVE" if blob.sentiment.polarity < -0.1 else "NEUTRAL",
                            "score": round(abs(blob.sentiment.polarity), 3)
                        }
                        
            except Exception as e:
                print(f"Transcription error: {e}")
        
        # Calculate overall score
        confidence = video_analysis.get("confidence_score", 5.0)
        professionalism = video_analysis.get("professionalism_score", 5.0)
        engagement = video_analysis.get("engagement_score", 5.0)
        overall_score = round((confidence + professionalism + engagement) / 3, 2)
        
        # Generate comprehensive feedback
        feedback_parts = []
        feedback_parts.append(f"üéØ Overall Score: {overall_score}/10\n")
        feedback_parts.append(f"üìä Confidence: {confidence}/10")
        feedback_parts.append(f"üëî Professionalism: {professionalism}/10")
        feedback_parts.append(f"üéØ Engagement: {engagement}/10\n")
        
        # Emotion analysis
        emotions = video_analysis.get("emotions", {})
        if emotions.get("dominant_emotion"):
            feedback_parts.append(f"üòä Dominant Emotion: {emotions['dominant_emotion'].title()}")
        
        # Facial analysis
        facial = video_analysis.get("facial_analysis", {})
        if facial.get("eye_contact") is not None:
            eye_contact_pct = int(facial["eye_contact"] * 100)
            feedback_parts.append(f"üëÅÔ∏è Eye Contact: {eye_contact_pct}%")
        
        # Audio analysis
        if audio_analysis.get("result"):
            feedback_parts.append(f"üé§ Voice Tone: {audio_analysis['result']}")
        
        # AI-enhanced sentiment and emotion
        if ai_text_analysis:
            sentiment = ai_text_analysis.get("sentiment", {})
            if sentiment.get("label"):
                feedback_parts.append(f"üí≠ Speech Sentiment: {sentiment['label']} ({sentiment.get('confidence', 'medium')} confidence)")
            
            emotion = ai_text_analysis.get("emotion", {})
            if emotion.get("dominant_emotion"):
                feedback_parts.append(f"üé≠ Speech Emotion: {emotion['dominant_emotion'].title()}")
            
            quality = ai_text_analysis.get("quality", {})
            if quality.get("quality_score"):
                quality_pct = int(quality["quality_score"] * 100)
                feedback_parts.append(f"üìù Speech Quality: {quality_pct}%")
            
            # AI-detected strengths
            strengths = ai_text_analysis.get("strengths", [])
            if strengths:
                feedback_parts.append("\n‚ú® Strengths:")
                for strength in strengths[:3]:
                    feedback_parts.append(f"  ‚Ä¢ {strength}")
        else:
            # Fallback sentiment
            sentiment = video_analysis.get("sentiment", {})
            if sentiment.get("label"):
                feedback_parts.append(f"üí≠ Sentiment: {sentiment['label'].title()}")
        
        # Recommendations (combine video and AI recommendations)
        recommendations = video_analysis.get("recommendations", [])
        if ai_text_analysis and ai_text_analysis.get("improvements"):
            recommendations.extend(ai_text_analysis["improvements"])
        
        if recommendations:
            feedback_parts.append("\nüí° Recommendations:")
            # Remove duplicates and limit to top 8
            unique_recs = list(dict.fromkeys(recommendations))[:8]
            for rec in unique_recs:
                feedback_parts.append(f"  ‚Ä¢ {rec}")
        
        feedback_text = "\n".join(feedback_parts)
        
        # Save attempt to database
        attempt = Attempt(
            user_id=user.id,
            question=question or "Video Interview Practice",
            score=overall_score,
            feedback=feedback_text,
            timestamp=datetime.utcnow()
        )
        db.add(attempt)
        
        # Update user stats
        user.attempts += 1
        user.total_score += overall_score
        db.commit()
        
        # Return comprehensive results
        return JSONResponse({
            "success": True,
            "message": "Video analyzed successfully",
            "score": overall_score,
            "feedback": feedback_text,
            "detailed_analysis": {
                "confidence_score": confidence,
                "professionalism_score": professionalism,
                "engagement_score": engagement,
                "emotions": emotions,
                "facial_analysis": facial,
                "body_language": video_analysis.get("body_language", {}),
                "audio_analysis": audio_analysis,
                "sentiment": video_analysis.get("sentiment", {}),
                "ai_text_analysis": ai_text_analysis,
                "recommendations": list(dict.fromkeys(recommendations))[:8],  # Unique, top 8
                "transcription": transcription,
                "validation": video_analysis.get("validation", {})
            },
            "video_url": f"/static/uploads/{safe_video_name}",
            "audio_url": f"/static/audio/{audio_filename}"
        })
        
    except Exception as e:
        print(f"Video analysis error: {e}")
        import traceback
        traceback.print_exc()
        
        # Fallback to basic analysis
        try:
            # Try audio extraction
            audio_result = "Not analyzed"
            try:
                extract_audio_from_video(video_path, audio_path)
                audio_analysis = analyze_audio_file(audio_path)
                audio_result = audio_analysis.get('result', 'Analyzed')
            except:
                pass
            
            basic_score = 7.0
            basic_feedback = f"‚úÖ Video uploaded successfully!\n\nüé§ Voice Analysis: {audio_result}\n\nüí° Recommendations:\n  ‚Ä¢ Keep practicing to improve your interview skills\n  ‚Ä¢ Focus on clear communication\n  ‚Ä¢ Maintain good eye contact with the camera"
            
            # Save basic attempt to database
            try:
                attempt = Attempt(
                    user_id=user.id,
                    question=question or "Video Interview Practice",
                    score=basic_score,
                    feedback=basic_feedback,
                    timestamp=datetime.utcnow()
                )
                db.add(attempt)
                user.attempts += 1
                user.total_score += basic_score
                db.commit()
            except Exception as db_error:
                print(f"Database save error: {db_error}")
            
            return JSONResponse({
                "success": True,
                "score": basic_score,
                "feedback": basic_feedback,
                "detailed_analysis": {
                    "confidence_score": 7.0,
                    "professionalism_score": 7.5,
                    "engagement_score": 7.2,
                    "emotions": {"dominant_emotion": "neutral"},
                    "facial_analysis": {},
                    "body_language": {},
                    "audio_analysis": {"result": audio_result},
                    "sentiment": {"label": "neutral"},
                    "recommendations": ["Keep practicing to improve your interview skills"],
                    "transcription": ""
                },
                "video_url": f"/static/uploads/{safe_video_name}",
                "audio_url": f"/static/audio/{audio_filename}",
                "note": "Basic analysis performed. For advanced features, ensure all dependencies are installed."
            })
        except Exception as fallback_error:
            print(f"Fallback analysis error: {fallback_error}")
            traceback.print_exc()
            return JSONResponse({
                "error": "Video processing failed",
                "details": str(e),
                "fallback_error": str(fallback_error)
            }, status_code=500)


# ---------------- Real-Time Video Analysis WebSocket ----------------
@app.websocket("/ws/realtime_analysis")
async def websocket_realtime_analysis(websocket: WebSocket):
    """
    WebSocket endpoint for real-time video analysis during recording
    Provides live feedback on emotions, eye contact, posture, etc.
    """
    await websocket.accept()
    
    try:
        from realtime_analysis import get_realtime_analyzer
        analyzer = get_realtime_analyzer()
        analyzer.reset()  # Reset for new session
        
        while True:
            # Receive frame data from client (base64 encoded image)
            data = await websocket.receive_json()
            
            if data.get("type") == "frame":
                try:
                    import base64
                    # Decode base64 image
                    img_data = base64.b64decode(data["frame"].split(",")[1])
                    nparr = np.frombuffer(img_data, np.uint8)
                    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    
                    # Analyze frame
                    result = analyzer.analyze_frame(frame)
                    
                    # Send results back to client
                    await websocket.send_json({
                        "type": "analysis",
                        "data": result
                    })
                
                except Exception as e:
                    await websocket.send_json({
                        "type": "error",
                        "message": str(e)
                    })
            
            elif data.get("type") == "end_session":
                # Get session summary
                summary = analyzer.get_session_summary()
                await websocket.send_json({
                    "type": "summary",
                    "data": summary
                })
                break
    
    except WebSocketDisconnect:
        print("WebSocket disconnected")
    except Exception as e:
        print(f"WebSocket error: {e}")
        try:
            await websocket.send_json({
                "type": "error",
                "message": str(e)
            })
        except:
            pass


# ---------------- API: Get Analysis Dashboard Data ----------------
@app.get("/api/analysis_dashboard/{attempt_id}")
def get_analysis_dashboard(attempt_id: int, request: Request, db=Depends(get_db)):
    """
    Get comprehensive analysis dashboard data for a specific attempt
    Includes timeline, metrics, and visualizations
    """
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"error": "Not authenticated"}, status_code=401)
    
    attempt = db.query(Attempt).filter_by(id=attempt_id, user_id=user.id).first()
    if not attempt:
        return JSONResponse({"error": "Attempt not found"}, status_code=404)
    
    # Parse detailed analysis from feedback if available
    # In production, you'd store this in a separate JSON column
    dashboard_data = {
        "attempt_id": attempt.id,
        "question": attempt.question,
        "score": attempt.score,
        "timestamp": attempt.timestamp.isoformat(),
        "feedback": attempt.feedback,
        "metrics": {
            "confidence": 7.0,
            "professionalism": 7.5,
            "engagement": 7.2,
            "authenticity": 7.0
        },
        "timeline": [],
        "recommendations": []
    }
    
    return JSONResponse(dashboard_data)


# ---------------- Password Reset (basic placeholders) ----------------
@app.get("/forgot_password", response_class=HTMLResponse)
def forgot_get(request: Request):
    return templates.TemplateResponse("forgot_password.html", {"request": request})

@app.post("/forgot_password")
def forgot_post(request: Request, email: str = Form(...), db=Depends(get_db)):
    email = email.strip().lower()
    user = db.query(User).filter_by(email=email).first()
    if not user:
        add_flash(request, "If that account exists, we sent a reset link (simulated).", "info")
        return RedirectResponse("/login", status_code=303)
    token = serializer.dumps(email, salt="password-reset-salt")
    # Here you'd send an email with the reset link. For now we flash the link (in real app use FastAPI-Mail)
    reset_url = f"/reset_password/{token}"
    add_flash(request, f"Reset link (for dev): {reset_url}", "info")
    return RedirectResponse("/login", status_code=303)

@app.get("/reset_password/{token}", response_class=HTMLResponse)
def reset_token_get(request: Request, token: str):
    try:
        email = serializer.loads(token, salt="password-reset-salt", max_age=3600)
    except SignatureExpired:
        add_flash(request, "Reset link expired.", "danger")
        return RedirectResponse("/forgot_password", status_code=303)
    except BadSignature:
        add_flash(request, "Invalid reset link.", "danger")
        return RedirectResponse("/forgot_password", status_code=303)
    return templates.TemplateResponse("reset_password.html", {"request": request})

@app.post("/reset_password/{token}")
def reset_token_post(request: Request, token: str, password1: str = Form(...), password2: str = Form(...), db=Depends(get_db)):
    if password1 != password2:
        add_flash(request, "Passwords do not match.", "danger")
        return RedirectResponse(f"/reset_password/{token}", status_code=303)
    try:
        email = serializer.loads(token, salt="password-reset-salt", max_age=3600)
    except Exception:
        add_flash(request, "Invalid or expired token.", "danger")
        return RedirectResponse("/forgot_password", status_code=303)
    user = db.query(User).filter_by(email=email).first()
    if not user:
        add_flash(request, "User not found.", "danger")
        return RedirectResponse("/register", status_code=303)
    user.password = PREFERRED_HASHER.hash(password1)
    db.commit()
    add_flash(request, "Password reset successful. Please log in.", "success")
    return RedirectResponse("/login", status_code=303)

# ---------------------------
# Patch: verify + migrate + replace broken login handler
# (Add this at the end of fastapi_app.py; does not modify existing lines)
# ---------------------------

def verify_and_migrate_password(candidate_pw: str, user_obj, db):
    """
    Verify candidate_pw against stored hash (user_obj.password).
    - Try Argon2 first (PREFERRED_HASHER).
    - If Argon2 verification fails, try legacy bcrypt (LEGACY_HASHER).
      If bcrypt verifies, re-hash using Argon2 and persist (automatic migration).
    Returns True on success, False otherwise.
    """
    stored_hash = getattr(user_obj, "password", None)
    if not stored_hash:
        return False

    # Try preferred (Argon2)
    try:
        if PREFERRED_HASHER.verify(candidate_pw, stored_hash):
            return True
    except Exception:
        # ignore and continue to legacy check
        pass

    # Fallback to legacy (bcrypt)
    try:
        if LEGACY_HASHER.verify(candidate_pw, stored_hash):
            # attempt to migrate to Argon2
            try:
                user_obj.password = PREFERRED_HASHER.hash(candidate_pw)
                db.add(user_obj)
                db.commit()
            except Exception:
                # migration failure shouldn't block login; rollback any partial changes
                try:
                    db.rollback()
                except Exception:
                    pass
            return True
    except Exception:
        pass

    return False


# build a correct login endpoint function (matching the route signature used earlier)
def _new_login_post(request: Request,
                    email: str = Form(...),
                    password: str = Form(...),
                    db=Depends(get_db)):
    """
    Replacement login endpoint. Will be hooked to the existing '/login' POST route.
    """
    # normalize
    email_norm = email.strip().lower()
    user = db.query(User).filter_by(email=email_norm).first()
    if user and verify_password(password, user.password):
    # consider migrating hash here if needed

        # set session and redirect
        request.session["user_id"] = user.id
        add_flash(request, "Login successful!", "success")
        return RedirectResponse("/", status_code=303)
    # else
    add_flash(request, "Invalid email or password.", "danger")
    return RedirectResponse("/login", status_code=303)


# Replace the existing registered route endpoint for POST /login with _new_login_post
# (This avoids editing the original decorator block ‚Äî we swap the function at runtime)
from fastapi.routing import APIRoute

_replaced = False
for i, route in enumerate(list(app.routes)):
    # APIRoute has .path and .methods
    try:
        if isinstance(route, APIRoute) and route.path == "/login" and ("POST" in route.methods):
            # patch the endpoint
            route.endpoint = _new_login_post
            # also update name to avoid confusion
            route.name = "_new_login_post"
            _replaced = True
            # only replace the first matching POST /login
            break
    except Exception:
        continue

if _replaced:
    print("‚úî Replaced existing POST /login endpoint with patched implementation (Argon2 + bcrypt fallback).")
else:
    # If replacement failed, still register a new route (non-destructive)
    app.post("/login")(_new_login_post)
    print("‚ö† Could not find existing POST /login route to replace ‚Äî registered a new /login POST endpoint instead.")

# End of patch

# ---------------------------
# Resume Analyzer & Generator Routes
# ---------------------------
from resume_analyzer import (
    analyze_resume_full,
    generate_mnc_resume_template
)
from resume_templates import (
    generate_resume,
    get_available_templates
)
from resume_pdf_generator import generate_pdf_resume

@app.get("/resume", response_class=HTMLResponse)
async def resume_page(request: Request, db=Depends(get_db)):
    """Resume analyzer and generator page"""
    user = get_current_user(request, db)
    if not user:
        return RedirectResponse("/login", status_code=303)
    
    return templates.TemplateResponse("resume.html", {
        "request": request,
        "user": user
    })


@app.post("/api/resume/analyze")
async def analyze_resume_api(
    request: Request,
    file: UploadFile = File(...),
    db=Depends(get_db)
):
    """API endpoint to analyze uploaded resume"""
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"success": False, "error": "Authentication required"}, status_code=401)
    
    try:
        # Read file content
        file_bytes = await file.read()
        
        # Validate file size (5MB max)
        if len(file_bytes) > 5 * 1024 * 1024:
            return JSONResponse({
                "success": False,
                "error": "File too large. Maximum size is 5MB."
            }, status_code=400)
        
        # Analyze resume
        result = analyze_resume_full(file_bytes, file.filename)
        
        return JSONResponse(result)
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)


@app.post("/api/resume/generate")
async def generate_resume_api(
    request: Request,
    data: dict = Body(...),
    db=Depends(get_db)
):
    """API endpoint to generate professional resume with templates"""
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"success": False, "error": "Authentication required"}, status_code=401)
    
    try:
        # Validate required fields
        required_fields = ['name', 'email', 'phone', 'location', 'summary']
        for field in required_fields:
            if not data.get(field):
                return JSONResponse({
                    "success": False,
                    "error": f"Missing required field: {field}"
                }, status_code=400)
        
        # Get template choice (default to professional)
        template_name = data.get('template', 'professional')
        
        # Generate resume using selected template
        resume_text = generate_resume(data, template_name)
        
        return JSONResponse({
            "success": True,
            "resume": resume_text,
            "template": template_name
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)


@app.get("/api/resume/templates")
async def get_templates_api(request: Request, db=Depends(get_db)):
    """API endpoint to get available resume templates"""
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"success": False, "error": "Authentication required"}, status_code=401)
    
    try:
        templates = get_available_templates()
        return JSONResponse({
            "success": True,
            "templates": templates
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)


@app.post("/api/resume/download-pdf")
async def download_resume_pdf(
    request: Request,
    data: dict = Body(...),
    db=Depends(get_db)
):
    """API endpoint to generate and download resume as PDF"""
    user = get_current_user(request, db)
    if not user:
        return JSONResponse({"success": False, "error": "Authentication required"}, status_code=401)
    
    try:
        # Validate required fields
        required_fields = ['name', 'email', 'phone', 'location', 'summary']
        for field in required_fields:
            if not data.get(field):
                return JSONResponse({
                    "success": False,
                    "error": f"Missing required field: {field}"
                }, status_code=400)
        
        # Get template choice (default to professional)
        template_name = data.get('template', 'professional')
        
        # Generate PDF
        pdf_buffer = generate_pdf_resume(data, template_name)
        
        # Create filename
        filename = f"resume_{data.get('name', 'document').replace(' ', '_')}.pdf"
        
        # Return PDF as download
        return Response(
            content=pdf_buffer.getvalue(),
            media_type="application/pdf",
            headers={
                "Content-Disposition": f"attachment; filename={filename}"
            }
        )
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)


# ---------------------------
# Run instructions (uvicorn)
# ---------------------------
if __name__ == "__main__":
    
    import uvicorn
    uvicorn.run("fastapi_app:app", host="0.0.0.0", port=8000, reload=True)
